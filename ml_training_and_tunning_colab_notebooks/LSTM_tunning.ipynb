{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"LSTM_tunning.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNEF4l4BbE7HPEmOSS6CgDa"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xPMmRnjM_5aq","executionInfo":{"status":"ok","timestamp":1623510373045,"user_tz":-180,"elapsed":1308,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"1f920c6d-6380-4f00-80fe-e6ebbed0f88a"},"source":["from google.colab import drive\n","drive.mount('/drive', force_remount=True)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Mounted at /drive\n","time: 1.09 s (started: 2021-06-12 15:06:13 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZBpRrd8C2Lyf","executionInfo":{"status":"ok","timestamp":1623510375864,"user_tz":-180,"elapsed":2822,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"aa2e5456-f5aa-47c6-813f-6d5b099d81c0"},"source":["!pip install ipython-autotime\n","%load_ext autotime\n","import pickle\n","import os\n","import time\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn import metrics\n","from tensorflow.keras import models\n","from tensorflow.keras import layers\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.model_selection import train_test_split\n","from sklearn.externals import joblib\n","import matplotlib.pyplot as plt\n","plt.rcParams[\"figure.figsize\"] = (20,10)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.7/dist-packages (0.3.1)\n","Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from ipython-autotime) (5.5.0)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.8.1)\n","Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (57.0.0)\n","Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (5.0.5)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.4.2)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (2.6.1)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (4.8.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (1.0.18)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->ipython-autotime) (0.7.5)\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->ipython-autotime) (0.2.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->ipython-autotime) (0.7.0)\n","Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (1.15.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->ipython-autotime) (0.2.5)\n","The autotime extension is already loaded. To reload it, use:\n","  %reload_ext autotime\n","time: 2.78 s (started: 2021-06-12 15:06:14 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T4MzSRrJQT3I","executionInfo":{"status":"ok","timestamp":1623510375865,"user_tz":-180,"elapsed":14,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"d83a12fd-d32c-4ac0-9f1c-2a16eb2b8d96"},"source":["import tensorflow as tf\n","print(\"Using Keras\",tf.keras.__version__)"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Using Keras 2.5.0\n","time: 1.24 ms (started: 2021-06-12 15:06:16 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"o2v1oFa9CUKE","executionInfo":{"status":"ok","timestamp":1623510375867,"user_tz":-180,"elapsed":10,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"fb6e63cf-4779-4985-f268-b483a6e5ecbc"},"source":["window_length = 30\n","timeframe = \"15minutes\"\n","classes = 2\n","candles = 1\n","network = None\n","scaler = None\n","batch_size = 128\n","\n","layer_tune = [1, 2]\n","neurons_tune = [64, 128]\n","dropout_tune = [0.5]\n","lr_tune = [0.001, 0.0001, 0.00001]\n","tune_results_file = \"/drive/My Drive/disertation/tunning_results_lstm_{}_window_{}.csv\".format(window_length, timeframe)"],"execution_count":19,"outputs":[{"output_type":"stream","text":["time: 6.22 ms (started: 2021-06-12 15:06:16 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9-1PYxUFl_A7","executionInfo":{"status":"ok","timestamp":1623510375868,"user_tz":-180,"elapsed":8,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"e720cb0b-8483-4804-800b-270f4e3c2b5f"},"source":["def extend_dataset_with_window_length(X, Y, window_length=window_length):\n","    new_x = []\n","    for i in range(len(X) - window_length+1):\n","        lst = []\n","        for j in range(i, i+window_length):\n","            lst.extend(X[j])\n","        new_x.append(lst)\n","    return np.array(new_x), Y[window_length-1:]\n","\n","def get_equal_class_distribution(X,Y):\n","    ys = pd.Series(Y)\n","    vs = ys.value_counts()\n","    required_of_each_class = vs.min()\n","    original_indexes = []\n","    for idx in vs.index:\n","        original_indexes.extend(ys[ys==idx].sample(n=required_of_each_class, replace=False, random_state=1).index)\n","    return X[original_indexes], Y[original_indexes]"],"execution_count":20,"outputs":[{"output_type":"stream","text":["time: 9.2 ms (started: 2021-06-12 15:06:16 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eFclaOA2kGk6","executionInfo":{"status":"ok","timestamp":1623510380810,"user_tz":-180,"elapsed":4949,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"0f6ab6b5-f4bb-4578-ee38-c62d4dcfc667"},"source":["train_df = pd.read_csv(\"/drive/My Drive/disertation/train_df_{}_{}_candles_{}_class.csv\".format(timeframe, candles, classes))\n","train_df = train_df.set_index(\"open_time\")\n","train_df.drop(columns=[\"close\"],inplace=True)\n","train_df.index = pd.to_datetime(train_df.index)\n","\n","data = train_df.to_numpy()\n","X = data[:,:-1]\n","Y = data[:,-1]\n","\n","X, Y = extend_dataset_with_window_length(X,Y)"],"execution_count":21,"outputs":[{"output_type":"stream","text":["time: 4.78 s (started: 2021-06-12 15:06:17 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bkqLXFCsDISI","executionInfo":{"status":"ok","timestamp":1623510380811,"user_tz":-180,"elapsed":15,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"9c0cd33e-7f67-464e-966e-63bd63a0c2be"},"source":["scaler = MinMaxScaler()\n","X = scaler.fit_transform(X)\n","\n","scaler_path = \"/drive/My Drive/disertation/lstms/lstm_scaler_{}_{}window.save\".format(timeframe, window_length)\n","joblib.dump(scaler, scaler_path)"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/drive/My Drive/disertation/lstms/lstm_scaler_15minutes_30window.save']"]},"metadata":{"tags":[]},"execution_count":22},{"output_type":"stream","text":["time: 179 ms (started: 2021-06-12 15:06:21 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mFKAhy5fejS2","executionInfo":{"status":"ok","timestamp":1623510380812,"user_tz":-180,"elapsed":12,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"f1a39994-c6b8-4b6a-c3ec-0ef45ce2ac44"},"source":["a,b = np.unique(Y, return_counts=True)\n","print(\"buy sell %\")\n","print(b)\n","print(b / sum(b))\n","\n","X,Y = get_equal_class_distribution(X,Y)\n","\n","a,b = np.unique(Y, return_counts=True)\n","print(\"buy sell %\")\n","print(b)\n","print(b / sum(b))\n","\n","n_features = X.shape[1] // window_length\n","n_timesteps = window_length\n","X = X.reshape(X.shape[0], n_timesteps, n_features)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["buy sell %\n","[10095  9076]\n","[0.5265766 0.4734234]\n","buy sell %\n","[9076 9076]\n","[0.5 0.5]\n","time: 61 ms (started: 2021-06-12 15:06:21 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qrItavmxpCmy","executionInfo":{"status":"ok","timestamp":1623510389841,"user_tz":-180,"elapsed":9039,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"6e368417-1faf-4a5f-9e4d-15032cbbcff7"},"source":["tune_df = pd.read_csv(\"/drive/My Drive/disertation/tune_df_{}_{}_candles_{}_class.csv\".format(timeframe, candles, classes))\n","tune_df = tune_df.set_index(\"open_time\")\n","tune_df.drop(columns=[\"close\"],inplace=True)\n","\n","data = tune_df.to_numpy()\n","X_tune = data[:,:-1]\n","Y_tune = data[:,-1]\n","\n","X_tune, Y_tune = extend_dataset_with_window_length(X_tune, Y_tune)\n","\n","X_tune = scaler.transform(X_tune)\n","X_tune = X_tune.reshape(X_tune.shape[0], n_timesteps, n_features)\n","\n","\n","test_df = pd.read_csv(\"/drive/My Drive/disertation/test_df_{}_{}_candles_{}_class.csv\".format(timeframe, candles, classes))\n","test_df = test_df.set_index(\"open_time\")\n","test_df.drop(columns=[\"close\"],inplace=True)\n","\n","data = test_df.to_numpy()\n","X_test = data[:,:-1]\n","Y_test = data[:,-1]\n","\n","X_test, Y_test = extend_dataset_with_window_length(X_test, Y_test)\n","\n","X_test = scaler.transform(X_test)\n","X_test = X_test.reshape(X_test.shape[0], n_timesteps, n_features)\n"],"execution_count":24,"outputs":[{"output_type":"stream","text":["time: 8.78 s (started: 2021-06-12 15:06:22 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c1u-AYSeHKlq","executionInfo":{"status":"ok","timestamp":1623510389842,"user_tz":-180,"elapsed":21,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"38404f65-de64-4287-9926-edbf1dbaad06"},"source":["a,b = np.unique(Y_tune, return_counts=True)\n","print(\"buy sell %\")\n","print(b)\n","print(b / sum(b))\n","tune_buy_percentage = (b/sum(b))[0]"],"execution_count":25,"outputs":[{"output_type":"stream","text":["buy sell %\n","[9757 9414]\n","[0.5089458 0.4910542]\n","time: 10.2 ms (started: 2021-06-12 15:06:30 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VfBAY_WyHLYl","executionInfo":{"status":"ok","timestamp":1623510389842,"user_tz":-180,"elapsed":18,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"541a83a2-97ef-41e0-b575-de882d237717"},"source":["a,b = np.unique(Y_test, return_counts=True)\n","print(\"buy sell %\")\n","print(b)\n","print(b / sum(b))\n","test_buy_percentage = (b/sum(b))[0]"],"execution_count":26,"outputs":[{"output_type":"stream","text":["buy sell %\n","[9657 9514]\n","[0.50372959 0.49627041]\n","time: 6.51 ms (started: 2021-06-12 15:06:30 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VV16kAMStkS0","executionInfo":{"status":"ok","timestamp":1623510389843,"user_tz":-180,"elapsed":17,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"37dfb172-a86f-4843-9891-83041d98675c"},"source":["def create_model(layers_count, neurons, lr, dropout):\n","    network = models.Sequential()\n","    if layers_count == 1:\n","        network.add(layers.LSTM(neurons, input_shape=(n_timesteps, n_features)))\n","        network.add(layers.Dropout(dropout))\n","    elif layers_count == 2:\n","        network.add(layers.LSTM(neurons, input_shape=(n_timesteps, n_features), return_sequences=True))\n","        network.add(layers.Dropout(dropout))\n","        network.add(layers.LSTM(neurons))\n","        network.add(layers.Dropout(dropout))\n","\n","    network.add(layers.Dense(neurons, activation='relu'))\n","\n","    network.add(layers.Dense(1, activation=\"sigmoid\"))\n","    loss = \"binary_crossentropy\"\n","    opt = tf.keras.optimizers.Adam(learning_rate=lr)\n","    network.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n","\n","    # print(network.summary())\n","\n","    return network"],"execution_count":27,"outputs":[{"output_type":"stream","text":["time: 15.2 ms (started: 2021-06-12 15:06:30 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AARxBTUTuCAD","executionInfo":{"status":"ok","timestamp":1623510389843,"user_tz":-180,"elapsed":15,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"4853e691-6853-455d-a35e-2d0380547317"},"source":["def train_network(network):\n","    callback_early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20, restore_best_weights=True)\n","    history = network.fit(X, Y, epochs=400, batch_size=batch_size, validation_data=(X_tune, Y_tune), callbacks=[callback_early_stop])\n","    return history\n","    # pd.DataFrame(history.history).plot(lw=2);"],"execution_count":28,"outputs":[{"output_type":"stream","text":["time: 3.99 ms (started: 2021-06-12 15:06:30 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZefbHr3MD4zK","executionInfo":{"status":"ok","timestamp":1623523628881,"user_tz":-180,"elapsed":3562759,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"acf9ca95-e526-4c58-9194-e6e5a6ec490e"},"source":["results = []\n","\n","attempt_number = 0\n","total_attempts = len(layer_tune) * len(neurons_tune) * len(lr_tune) * len(dropout_tune)\n","\n","for layers_count in layer_tune:\n","    for neurons in neurons_tune:\n","        for lr in lr_tune:\n","            for dropout in dropout_tune:\n","                attempt_number += 1\n","                print(\"Attempt {}/{}\".format(attempt_number, total_attempts))\n","\n","                network = create_model(layers_count=layers_count, neurons=neurons, lr=lr, dropout=dropout)\n","                t = time.time()\n","                history = train_network(network)\n","                train_time = time.time() - t\n","\n","                model_file = \"/drive/My Drive/disertation/lstms/lstm_{}__{}_{}window.h5\".format(attempt_number, timeframe, window_length)\n","\n","                if os.path.exists(model_file):\n","                    raise Exception(\"file exists!\")\n","                network.save(model_file)\n","\n","                Y_predicted = network.predict_classes(X)\n","                report = metrics.classification_report(Y, Y_predicted, digits=3, output_dict=True)\n","                f1_train = report['weighted avg']['f1-score']\n","                acc_train = report[\"accuracy\"]\n","\n","                Y_tune_predicted = network.predict_classes(X_tune)\n","                report = metrics.classification_report(Y_tune, Y_tune_predicted, digits=3, output_dict=True)\n","                f1_tune = report['weighted avg']['f1-score']\n","                acc_tune = report[\"accuracy\"]\n","\n","                Y_test_predicted = network.predict_classes(X_test)\n","                report = metrics.classification_report(Y_test, Y_test_predicted, digits=3, output_dict=True)\n","                f1_test = report['weighted avg']['f1-score']\n","                acc_test = report['accuracy']\n","\n","                r = {\n","                    \"attempt\": attempt_number,\n","                    \"layers\": layers_count,\n","                    \"neurons\": neurons,\n","                    \"lr\": lr,\n","                    \"train_time\": train_time,\n","                    \"epochs\": len(history.epoch),\n","                    \"train_acc\": acc_train,\n","                    \"train_f1\": f1_train,\n","                    \"tune_acc\": acc_tune,\n","                    \"tune_f1\": f1_tune,\n","                    \"test_acc\": acc_test,\n","                    \"test_f1\": f1_test,\n","                    \"tune_buy_percentage\": tune_buy_percentage,\n","                    \"test_buy_percentage\": test_buy_percentage\n","                }\n","                results.append(r)\n","                print(pd.DataFrame(results)[[\"train_acc\", \"train_f1\", \"tune_acc\", \"tune_f1\", \"test_acc\", \"test_f1\"]])"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Attempt 1/12\n","Epoch 1/400\n","142/142 [==============================] - 9s 49ms/step - loss: 0.6949 - accuracy: 0.5012 - val_loss: 0.6925 - val_accuracy: 0.5188\n","Epoch 2/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6937 - accuracy: 0.5069 - val_loss: 0.6922 - val_accuracy: 0.5172\n","Epoch 3/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6933 - accuracy: 0.5086 - val_loss: 0.6927 - val_accuracy: 0.5155\n","Epoch 4/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6933 - accuracy: 0.5046 - val_loss: 0.6923 - val_accuracy: 0.5181\n","Epoch 5/400\n","142/142 [==============================] - 6s 45ms/step - loss: 0.6925 - accuracy: 0.5117 - val_loss: 0.6926 - val_accuracy: 0.5115\n","Epoch 6/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6926 - accuracy: 0.5127 - val_loss: 0.6919 - val_accuracy: 0.5192\n","Epoch 7/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6919 - accuracy: 0.5131 - val_loss: 0.6920 - val_accuracy: 0.5131\n","Epoch 8/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6923 - accuracy: 0.5155 - val_loss: 0.6924 - val_accuracy: 0.5122\n","Epoch 9/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6906 - accuracy: 0.5216 - val_loss: 0.6915 - val_accuracy: 0.5234\n","Epoch 10/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6894 - accuracy: 0.5247 - val_loss: 0.6915 - val_accuracy: 0.5304\n","Epoch 11/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6893 - accuracy: 0.5227 - val_loss: 0.6909 - val_accuracy: 0.5261\n","Epoch 12/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6893 - accuracy: 0.5234 - val_loss: 0.6908 - val_accuracy: 0.5325\n","Epoch 13/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6889 - accuracy: 0.5247 - val_loss: 0.6904 - val_accuracy: 0.5306\n","Epoch 14/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6884 - accuracy: 0.5275 - val_loss: 0.6901 - val_accuracy: 0.5279\n","Epoch 15/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6879 - accuracy: 0.5306 - val_loss: 0.6898 - val_accuracy: 0.5371\n","Epoch 16/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6875 - accuracy: 0.5327 - val_loss: 0.6891 - val_accuracy: 0.5389\n","Epoch 17/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6885 - accuracy: 0.5282 - val_loss: 0.6892 - val_accuracy: 0.5401\n","Epoch 18/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6860 - accuracy: 0.5397 - val_loss: 0.6891 - val_accuracy: 0.5398\n","Epoch 19/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6865 - accuracy: 0.5317 - val_loss: 0.6895 - val_accuracy: 0.5349\n","Epoch 20/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6859 - accuracy: 0.5401 - val_loss: 0.6898 - val_accuracy: 0.5345\n","Epoch 21/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6860 - accuracy: 0.5388 - val_loss: 0.6902 - val_accuracy: 0.5388\n","Epoch 22/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6858 - accuracy: 0.5379 - val_loss: 0.6886 - val_accuracy: 0.5363\n","Epoch 23/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6851 - accuracy: 0.5408 - val_loss: 0.6897 - val_accuracy: 0.5316\n","Epoch 24/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6851 - accuracy: 0.5387 - val_loss: 0.6886 - val_accuracy: 0.5379\n","Epoch 25/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6849 - accuracy: 0.5403 - val_loss: 0.6892 - val_accuracy: 0.5355\n","Epoch 26/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6852 - accuracy: 0.5439 - val_loss: 0.6884 - val_accuracy: 0.5389\n","Epoch 27/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6850 - accuracy: 0.5383 - val_loss: 0.6895 - val_accuracy: 0.5329\n","Epoch 28/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6842 - accuracy: 0.5428 - val_loss: 0.6891 - val_accuracy: 0.5354\n","Epoch 29/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6848 - accuracy: 0.5375 - val_loss: 0.6885 - val_accuracy: 0.5392\n","Epoch 30/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6844 - accuracy: 0.5393 - val_loss: 0.6887 - val_accuracy: 0.5366\n","Epoch 31/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6838 - accuracy: 0.5441 - val_loss: 0.6912 - val_accuracy: 0.5339\n","Epoch 32/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6836 - accuracy: 0.5440 - val_loss: 0.6892 - val_accuracy: 0.5363\n","Epoch 33/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6839 - accuracy: 0.5456 - val_loss: 0.6891 - val_accuracy: 0.5371\n","Epoch 34/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6844 - accuracy: 0.5432 - val_loss: 0.6901 - val_accuracy: 0.5355\n","Epoch 35/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6834 - accuracy: 0.5455 - val_loss: 0.6886 - val_accuracy: 0.5391\n","Epoch 36/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6836 - accuracy: 0.5451 - val_loss: 0.6885 - val_accuracy: 0.5385\n","Epoch 37/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6839 - accuracy: 0.5434 - val_loss: 0.6885 - val_accuracy: 0.5372\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["   train_acc  train_f1  tune_acc   tune_f1  test_acc   test_f1\n","0   0.542364  0.542234  0.540139  0.537295  0.526994  0.525064\n","Attempt 2/12\n","Epoch 1/400\n","142/142 [==============================] - 8s 47ms/step - loss: 0.6957 - accuracy: 0.5025 - val_loss: 0.6927 - val_accuracy: 0.5129\n","Epoch 2/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6940 - accuracy: 0.5017 - val_loss: 0.6929 - val_accuracy: 0.5087\n","Epoch 3/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6934 - accuracy: 0.5021 - val_loss: 0.6928 - val_accuracy: 0.5119\n","Epoch 4/400\n","142/142 [==============================] - 7s 47ms/step - loss: 0.6934 - accuracy: 0.5049 - val_loss: 0.6928 - val_accuracy: 0.5126\n","Epoch 5/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6929 - accuracy: 0.5083 - val_loss: 0.6924 - val_accuracy: 0.5196\n","Epoch 6/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6931 - accuracy: 0.5088 - val_loss: 0.6922 - val_accuracy: 0.5252\n","Epoch 7/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6931 - accuracy: 0.5068 - val_loss: 0.6923 - val_accuracy: 0.5133\n","Epoch 8/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6925 - accuracy: 0.5170 - val_loss: 0.6927 - val_accuracy: 0.5065\n","Epoch 9/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6920 - accuracy: 0.5219 - val_loss: 0.6923 - val_accuracy: 0.5206\n","Epoch 10/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6920 - accuracy: 0.5136 - val_loss: 0.6916 - val_accuracy: 0.5256\n","Epoch 11/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6909 - accuracy: 0.5160 - val_loss: 0.6915 - val_accuracy: 0.5264\n","Epoch 12/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6899 - accuracy: 0.5208 - val_loss: 0.6915 - val_accuracy: 0.5314\n","Epoch 13/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6896 - accuracy: 0.5218 - val_loss: 0.6909 - val_accuracy: 0.5311\n","Epoch 14/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6893 - accuracy: 0.5237 - val_loss: 0.6907 - val_accuracy: 0.5286\n","Epoch 15/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6890 - accuracy: 0.5279 - val_loss: 0.6919 - val_accuracy: 0.5208\n","Epoch 16/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6886 - accuracy: 0.5219 - val_loss: 0.6906 - val_accuracy: 0.5300\n","Epoch 17/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6881 - accuracy: 0.5289 - val_loss: 0.6904 - val_accuracy: 0.5312\n","Epoch 18/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6875 - accuracy: 0.5312 - val_loss: 0.6897 - val_accuracy: 0.5351\n","Epoch 19/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6869 - accuracy: 0.5317 - val_loss: 0.6895 - val_accuracy: 0.5342\n","Epoch 20/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6900 - accuracy: 0.5242 - val_loss: 0.6899 - val_accuracy: 0.5418\n","Epoch 21/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6894 - accuracy: 0.5291 - val_loss: 0.6898 - val_accuracy: 0.5321\n","Epoch 22/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6869 - accuracy: 0.5340 - val_loss: 0.6893 - val_accuracy: 0.5337\n","Epoch 23/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6861 - accuracy: 0.5345 - val_loss: 0.6893 - val_accuracy: 0.5318\n","Epoch 24/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6856 - accuracy: 0.5382 - val_loss: 0.6889 - val_accuracy: 0.5409\n","Epoch 25/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6863 - accuracy: 0.5353 - val_loss: 0.6890 - val_accuracy: 0.5384\n","Epoch 26/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6860 - accuracy: 0.5395 - val_loss: 0.6886 - val_accuracy: 0.5405\n","Epoch 27/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6859 - accuracy: 0.5370 - val_loss: 0.6886 - val_accuracy: 0.5413\n","Epoch 28/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6850 - accuracy: 0.5410 - val_loss: 0.6891 - val_accuracy: 0.5335\n","Epoch 29/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6851 - accuracy: 0.5432 - val_loss: 0.6891 - val_accuracy: 0.5341\n","Epoch 30/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6854 - accuracy: 0.5430 - val_loss: 0.6891 - val_accuracy: 0.5398\n","Epoch 31/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6849 - accuracy: 0.5419 - val_loss: 0.6890 - val_accuracy: 0.5359\n","Epoch 32/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6852 - accuracy: 0.5409 - val_loss: 0.6885 - val_accuracy: 0.5395\n","Epoch 33/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6844 - accuracy: 0.5438 - val_loss: 0.6889 - val_accuracy: 0.5377\n","Epoch 34/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6839 - accuracy: 0.5486 - val_loss: 0.6901 - val_accuracy: 0.5325\n","Epoch 35/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6840 - accuracy: 0.5429 - val_loss: 0.6899 - val_accuracy: 0.5343\n","Epoch 36/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6842 - accuracy: 0.5431 - val_loss: 0.6890 - val_accuracy: 0.5379\n","Epoch 37/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6850 - accuracy: 0.5356 - val_loss: 0.6892 - val_accuracy: 0.5345\n","Epoch 38/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6836 - accuracy: 0.5452 - val_loss: 0.6890 - val_accuracy: 0.5377\n","Epoch 39/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6849 - accuracy: 0.5397 - val_loss: 0.6893 - val_accuracy: 0.5398\n","Epoch 40/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6840 - accuracy: 0.5440 - val_loss: 0.6890 - val_accuracy: 0.5387\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["   train_acc  train_f1  tune_acc   tune_f1  test_acc   test_f1\n","0   0.542364  0.542234  0.540139  0.537295  0.526994  0.525064\n","1   0.534762  0.533756  0.541808  0.541606  0.519326  0.516555\n","Attempt 3/12\n","Epoch 1/400\n","142/142 [==============================] - 8s 47ms/step - loss: 0.6951 - accuracy: 0.5023 - val_loss: 0.6932 - val_accuracy: 0.5089\n","Epoch 2/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6939 - accuracy: 0.5051 - val_loss: 0.6927 - val_accuracy: 0.5087\n","Epoch 3/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6932 - accuracy: 0.5056 - val_loss: 0.6927 - val_accuracy: 0.5207\n","Epoch 4/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6930 - accuracy: 0.5121 - val_loss: 0.6932 - val_accuracy: 0.4921\n","Epoch 5/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6928 - accuracy: 0.5153 - val_loss: 0.6923 - val_accuracy: 0.5207\n","Epoch 6/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6920 - accuracy: 0.5193 - val_loss: 0.6918 - val_accuracy: 0.5273\n","Epoch 7/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6922 - accuracy: 0.5110 - val_loss: 0.6921 - val_accuracy: 0.5185\n","Epoch 8/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6910 - accuracy: 0.5098 - val_loss: 0.6926 - val_accuracy: 0.5052\n","Epoch 9/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6895 - accuracy: 0.5214 - val_loss: 0.6914 - val_accuracy: 0.5279\n","Epoch 10/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6897 - accuracy: 0.5186 - val_loss: 0.6910 - val_accuracy: 0.5281\n","Epoch 11/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6892 - accuracy: 0.5234 - val_loss: 0.6914 - val_accuracy: 0.5252\n","Epoch 12/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6886 - accuracy: 0.5203 - val_loss: 0.6907 - val_accuracy: 0.5272\n","Epoch 13/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6881 - accuracy: 0.5224 - val_loss: 0.6901 - val_accuracy: 0.5351\n","Epoch 14/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6880 - accuracy: 0.5256 - val_loss: 0.6906 - val_accuracy: 0.5253\n","Epoch 15/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6870 - accuracy: 0.5309 - val_loss: 0.6906 - val_accuracy: 0.5345\n","Epoch 16/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6875 - accuracy: 0.5264 - val_loss: 0.6903 - val_accuracy: 0.5234\n","Epoch 17/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6867 - accuracy: 0.5305 - val_loss: 0.6890 - val_accuracy: 0.5374\n","Epoch 18/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6867 - accuracy: 0.5361 - val_loss: 0.6889 - val_accuracy: 0.5398\n","Epoch 19/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6866 - accuracy: 0.5349 - val_loss: 0.6887 - val_accuracy: 0.5372\n","Epoch 20/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6856 - accuracy: 0.5375 - val_loss: 0.6888 - val_accuracy: 0.5372\n","Epoch 21/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6858 - accuracy: 0.5350 - val_loss: 0.6890 - val_accuracy: 0.5389\n","Epoch 22/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6858 - accuracy: 0.5404 - val_loss: 0.6893 - val_accuracy: 0.5343\n","Epoch 23/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6852 - accuracy: 0.5386 - val_loss: 0.6887 - val_accuracy: 0.5401\n","Epoch 24/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6855 - accuracy: 0.5391 - val_loss: 0.6884 - val_accuracy: 0.5393\n","Epoch 25/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6850 - accuracy: 0.5426 - val_loss: 0.6882 - val_accuracy: 0.5396\n","Epoch 26/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6848 - accuracy: 0.5398 - val_loss: 0.6887 - val_accuracy: 0.5408\n","Epoch 27/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6848 - accuracy: 0.5389 - val_loss: 0.6893 - val_accuracy: 0.5353\n","Epoch 28/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6839 - accuracy: 0.5454 - val_loss: 0.6886 - val_accuracy: 0.5413\n","Epoch 29/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6844 - accuracy: 0.5392 - val_loss: 0.6889 - val_accuracy: 0.5370\n","Epoch 30/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6836 - accuracy: 0.5437 - val_loss: 0.6888 - val_accuracy: 0.5386\n","Epoch 31/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6837 - accuracy: 0.5450 - val_loss: 0.6889 - val_accuracy: 0.5389\n","Epoch 32/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6843 - accuracy: 0.5424 - val_loss: 0.6888 - val_accuracy: 0.5398\n","Epoch 33/400\n","142/142 [==============================] - 6s 43ms/step - loss: 0.6839 - accuracy: 0.5425 - val_loss: 0.6888 - val_accuracy: 0.5387\n","Epoch 34/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6837 - accuracy: 0.5459 - val_loss: 0.6886 - val_accuracy: 0.5388\n","Epoch 35/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6840 - accuracy: 0.5452 - val_loss: 0.6895 - val_accuracy: 0.5350\n","Epoch 36/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6835 - accuracy: 0.5436 - val_loss: 0.6891 - val_accuracy: 0.5360\n","Epoch 37/400\n","142/142 [==============================] - 6s 45ms/step - loss: 0.6836 - accuracy: 0.5438 - val_loss: 0.6896 - val_accuracy: 0.5348\n","Epoch 38/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6837 - accuracy: 0.5424 - val_loss: 0.6889 - val_accuracy: 0.5391\n","Epoch 39/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6823 - accuracy: 0.5467 - val_loss: 0.6901 - val_accuracy: 0.5360\n","Epoch 40/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6832 - accuracy: 0.5433 - val_loss: 0.6898 - val_accuracy: 0.5373\n","Epoch 41/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6835 - accuracy: 0.5458 - val_loss: 0.6891 - val_accuracy: 0.5379\n","Epoch 42/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6832 - accuracy: 0.5453 - val_loss: 0.6895 - val_accuracy: 0.5382\n","Epoch 43/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6827 - accuracy: 0.5483 - val_loss: 0.6897 - val_accuracy: 0.5348\n","Epoch 44/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6824 - accuracy: 0.5493 - val_loss: 0.6896 - val_accuracy: 0.5334\n","Epoch 45/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6824 - accuracy: 0.5470 - val_loss: 0.6905 - val_accuracy: 0.5370\n","Epoch 46/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6822 - accuracy: 0.5492 - val_loss: 0.6893 - val_accuracy: 0.5393\n","Epoch 47/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6824 - accuracy: 0.5447 - val_loss: 0.6894 - val_accuracy: 0.5373\n","Epoch 48/400\n","142/142 [==============================] - 6s 44ms/step - loss: 0.6823 - accuracy: 0.5465 - val_loss: 0.6921 - val_accuracy: 0.5336\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["   train_acc  train_f1  tune_acc   tune_f1  test_acc   test_f1\n","0   0.542364  0.542234  0.540139  0.537295  0.526994  0.525064\n","1   0.534762  0.533756  0.541808  0.541606  0.519326  0.516555\n","2   0.547543  0.546179  0.541286  0.541223  0.529185  0.527102\n","Attempt 4/12\n","Epoch 1/400\n","142/142 [==============================] - 18s 113ms/step - loss: 0.6958 - accuracy: 0.4994 - val_loss: 0.6932 - val_accuracy: 0.5089\n","Epoch 2/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6936 - accuracy: 0.5074 - val_loss: 0.6929 - val_accuracy: 0.5089\n","Epoch 3/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6936 - accuracy: 0.5014 - val_loss: 0.6937 - val_accuracy: 0.4911\n","Epoch 4/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6932 - accuracy: 0.5120 - val_loss: 0.6920 - val_accuracy: 0.5232\n","Epoch 5/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6928 - accuracy: 0.5148 - val_loss: 0.6917 - val_accuracy: 0.5259\n","Epoch 6/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6927 - accuracy: 0.5095 - val_loss: 0.6927 - val_accuracy: 0.5073\n","Epoch 7/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6926 - accuracy: 0.5147 - val_loss: 0.6920 - val_accuracy: 0.5300\n","Epoch 8/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6921 - accuracy: 0.5084 - val_loss: 0.6923 - val_accuracy: 0.5173\n","Epoch 9/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6917 - accuracy: 0.5145 - val_loss: 0.6919 - val_accuracy: 0.5239\n","Epoch 10/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6907 - accuracy: 0.5198 - val_loss: 0.6908 - val_accuracy: 0.5299\n","Epoch 11/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6898 - accuracy: 0.5221 - val_loss: 0.6914 - val_accuracy: 0.5314\n","Epoch 12/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6921 - accuracy: 0.5220 - val_loss: 0.6918 - val_accuracy: 0.5309\n","Epoch 13/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6899 - accuracy: 0.5242 - val_loss: 0.6905 - val_accuracy: 0.5333\n","Epoch 14/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6882 - accuracy: 0.5306 - val_loss: 0.6897 - val_accuracy: 0.5312\n","Epoch 15/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6879 - accuracy: 0.5234 - val_loss: 0.6893 - val_accuracy: 0.5326\n","Epoch 16/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6879 - accuracy: 0.5330 - val_loss: 0.6888 - val_accuracy: 0.5403\n","Epoch 17/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6870 - accuracy: 0.5296 - val_loss: 0.6890 - val_accuracy: 0.5382\n","Epoch 18/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6862 - accuracy: 0.5380 - val_loss: 0.6890 - val_accuracy: 0.5403\n","Epoch 19/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6868 - accuracy: 0.5328 - val_loss: 0.6929 - val_accuracy: 0.5228\n","Epoch 20/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6863 - accuracy: 0.5351 - val_loss: 0.6895 - val_accuracy: 0.5367\n","Epoch 21/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6872 - accuracy: 0.5354 - val_loss: 0.6891 - val_accuracy: 0.5336\n","Epoch 22/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6862 - accuracy: 0.5399 - val_loss: 0.6888 - val_accuracy: 0.5388\n","Epoch 23/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6849 - accuracy: 0.5381 - val_loss: 0.6889 - val_accuracy: 0.5368\n","Epoch 24/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6863 - accuracy: 0.5388 - val_loss: 0.6893 - val_accuracy: 0.5397\n","Epoch 25/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6849 - accuracy: 0.5462 - val_loss: 0.6901 - val_accuracy: 0.5283\n","Epoch 26/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6848 - accuracy: 0.5407 - val_loss: 0.6887 - val_accuracy: 0.5392\n","Epoch 27/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6845 - accuracy: 0.5416 - val_loss: 0.6893 - val_accuracy: 0.5363\n","Epoch 28/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6841 - accuracy: 0.5421 - val_loss: 0.6890 - val_accuracy: 0.5371\n","Epoch 29/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6843 - accuracy: 0.5457 - val_loss: 0.6896 - val_accuracy: 0.5361\n","Epoch 30/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6840 - accuracy: 0.5461 - val_loss: 0.6901 - val_accuracy: 0.5321\n","Epoch 31/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6847 - accuracy: 0.5446 - val_loss: 0.6895 - val_accuracy: 0.5348\n","Epoch 32/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6837 - accuracy: 0.5420 - val_loss: 0.6883 - val_accuracy: 0.5398\n","Epoch 33/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6864 - accuracy: 0.5388 - val_loss: 0.6893 - val_accuracy: 0.5367\n","Epoch 34/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6872 - accuracy: 0.5420 - val_loss: 0.6921 - val_accuracy: 0.5302\n","Epoch 35/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6835 - accuracy: 0.5409 - val_loss: 0.6891 - val_accuracy: 0.5379\n","Epoch 36/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6837 - accuracy: 0.5392 - val_loss: 0.6907 - val_accuracy: 0.5348\n","Epoch 37/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6833 - accuracy: 0.5433 - val_loss: 0.6896 - val_accuracy: 0.5359\n","Epoch 38/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6834 - accuracy: 0.5437 - val_loss: 0.6896 - val_accuracy: 0.5358\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["   train_acc  train_f1  tune_acc   tune_f1  test_acc   test_f1\n","0   0.542364  0.542234  0.540139  0.537295  0.526994  0.525064\n","1   0.534762  0.533756  0.541808  0.541606  0.519326  0.516555\n","2   0.547543  0.546179  0.541286  0.541223  0.529185  0.527102\n","3   0.544623  0.543158  0.540347  0.540219  0.527046  0.521535\n","Attempt 5/12\n","Epoch 1/400\n","142/142 [==============================] - 18s 114ms/step - loss: 0.6954 - accuracy: 0.5078 - val_loss: 0.6925 - val_accuracy: 0.5165\n","Epoch 2/400\n","142/142 [==============================] - 15s 109ms/step - loss: 0.6941 - accuracy: 0.5017 - val_loss: 0.6926 - val_accuracy: 0.5147\n","Epoch 3/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6936 - accuracy: 0.5054 - val_loss: 0.6933 - val_accuracy: 0.4981\n","Epoch 4/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6927 - accuracy: 0.5101 - val_loss: 0.6952 - val_accuracy: 0.4911\n","Epoch 5/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6933 - accuracy: 0.5034 - val_loss: 0.6932 - val_accuracy: 0.4923\n","Epoch 6/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6925 - accuracy: 0.5112 - val_loss: 0.6925 - val_accuracy: 0.5170\n","Epoch 7/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6906 - accuracy: 0.5142 - val_loss: 0.6918 - val_accuracy: 0.5243\n","Epoch 8/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6907 - accuracy: 0.5204 - val_loss: 0.6917 - val_accuracy: 0.5240\n","Epoch 9/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6904 - accuracy: 0.5158 - val_loss: 0.6913 - val_accuracy: 0.5277\n","Epoch 10/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6896 - accuracy: 0.5215 - val_loss: 0.6910 - val_accuracy: 0.5276\n","Epoch 11/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6885 - accuracy: 0.5237 - val_loss: 0.6910 - val_accuracy: 0.5269\n","Epoch 12/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6884 - accuracy: 0.5234 - val_loss: 0.7053 - val_accuracy: 0.5245\n","Epoch 13/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6896 - accuracy: 0.5224 - val_loss: 0.6904 - val_accuracy: 0.5335\n","Epoch 14/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6881 - accuracy: 0.5255 - val_loss: 0.6901 - val_accuracy: 0.5354\n","Epoch 15/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6876 - accuracy: 0.5295 - val_loss: 0.6897 - val_accuracy: 0.5362\n","Epoch 16/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6874 - accuracy: 0.5299 - val_loss: 0.6901 - val_accuracy: 0.5363\n","Epoch 17/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6869 - accuracy: 0.5307 - val_loss: 0.6890 - val_accuracy: 0.5359\n","Epoch 18/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6867 - accuracy: 0.5305 - val_loss: 0.6893 - val_accuracy: 0.5395\n","Epoch 19/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6865 - accuracy: 0.5345 - val_loss: 0.6894 - val_accuracy: 0.5345\n","Epoch 20/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6863 - accuracy: 0.5357 - val_loss: 0.6890 - val_accuracy: 0.5401\n","Epoch 21/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6854 - accuracy: 0.5386 - val_loss: 0.6890 - val_accuracy: 0.5387\n","Epoch 22/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6856 - accuracy: 0.5391 - val_loss: 0.6897 - val_accuracy: 0.5309\n","Epoch 23/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6854 - accuracy: 0.5409 - val_loss: 0.6888 - val_accuracy: 0.5396\n","Epoch 24/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6849 - accuracy: 0.5407 - val_loss: 0.6883 - val_accuracy: 0.5412\n","Epoch 25/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6849 - accuracy: 0.5416 - val_loss: 0.6887 - val_accuracy: 0.5397\n","Epoch 26/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6846 - accuracy: 0.5415 - val_loss: 0.6881 - val_accuracy: 0.5394\n","Epoch 27/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6847 - accuracy: 0.5425 - val_loss: 0.6885 - val_accuracy: 0.5397\n","Epoch 28/400\n","142/142 [==============================] - 16s 114ms/step - loss: 0.6845 - accuracy: 0.5402 - val_loss: 0.6885 - val_accuracy: 0.5382\n","Epoch 29/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6843 - accuracy: 0.5397 - val_loss: 0.6891 - val_accuracy: 0.5378\n","Epoch 30/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6841 - accuracy: 0.5431 - val_loss: 0.6903 - val_accuracy: 0.5321\n","Epoch 31/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6841 - accuracy: 0.5452 - val_loss: 0.6887 - val_accuracy: 0.5396\n","Epoch 32/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6840 - accuracy: 0.5466 - val_loss: 0.6885 - val_accuracy: 0.5411\n","Epoch 33/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6840 - accuracy: 0.5409 - val_loss: 0.6887 - val_accuracy: 0.5390\n","Epoch 34/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6838 - accuracy: 0.5461 - val_loss: 0.6888 - val_accuracy: 0.5393\n","Epoch 35/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6831 - accuracy: 0.5439 - val_loss: 0.6908 - val_accuracy: 0.5352\n","Epoch 36/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6829 - accuracy: 0.5436 - val_loss: 0.6892 - val_accuracy: 0.5383\n","Epoch 37/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6834 - accuracy: 0.5474 - val_loss: 0.6898 - val_accuracy: 0.5334\n","Epoch 38/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6836 - accuracy: 0.5452 - val_loss: 0.6891 - val_accuracy: 0.5393\n","Epoch 39/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6827 - accuracy: 0.5444 - val_loss: 0.6903 - val_accuracy: 0.5360\n","Epoch 40/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6849 - accuracy: 0.5430 - val_loss: 0.6906 - val_accuracy: 0.5370\n","Epoch 41/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6884 - accuracy: 0.5393 - val_loss: 0.6898 - val_accuracy: 0.5368\n","Epoch 42/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6843 - accuracy: 0.5399 - val_loss: 0.6896 - val_accuracy: 0.5377\n","Epoch 43/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6831 - accuracy: 0.5458 - val_loss: 0.6897 - val_accuracy: 0.5367\n","Epoch 44/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6828 - accuracy: 0.5441 - val_loss: 0.6893 - val_accuracy: 0.5394\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["   train_acc  train_f1  tune_acc   tune_f1  test_acc   test_f1\n","0   0.542364  0.542234  0.540139  0.537295  0.526994  0.525064\n","1   0.534762  0.533756  0.541808  0.541606  0.519326  0.516555\n","2   0.547543  0.546179  0.541286  0.541223  0.529185  0.527102\n","3   0.544623  0.543158  0.540347  0.540219  0.527046  0.521535\n","4   0.545670  0.544153  0.541234  0.540168  0.527411  0.519087\n","Attempt 6/12\n","Epoch 1/400\n","142/142 [==============================] - 18s 113ms/step - loss: 0.6949 - accuracy: 0.5088 - val_loss: 0.6943 - val_accuracy: 0.4911\n","Epoch 2/400\n","142/142 [==============================] - 16s 109ms/step - loss: 0.6937 - accuracy: 0.5025 - val_loss: 0.6934 - val_accuracy: 0.4914\n","Epoch 3/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6935 - accuracy: 0.5060 - val_loss: 0.6931 - val_accuracy: 0.5089\n","Epoch 4/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6931 - accuracy: 0.5116 - val_loss: 0.6927 - val_accuracy: 0.5236\n","Epoch 5/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6929 - accuracy: 0.5107 - val_loss: 0.6923 - val_accuracy: 0.5207\n","Epoch 6/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6928 - accuracy: 0.5117 - val_loss: 0.6929 - val_accuracy: 0.5044\n","Epoch 7/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6929 - accuracy: 0.5056 - val_loss: 0.6923 - val_accuracy: 0.5104\n","Epoch 8/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6916 - accuracy: 0.5170 - val_loss: 0.6925 - val_accuracy: 0.5201\n","Epoch 9/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6912 - accuracy: 0.5145 - val_loss: 0.6920 - val_accuracy: 0.5255\n","Epoch 10/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6920 - accuracy: 0.5164 - val_loss: 0.6918 - val_accuracy: 0.5258\n","Epoch 11/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6909 - accuracy: 0.5151 - val_loss: 0.6919 - val_accuracy: 0.5279\n","Epoch 12/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6898 - accuracy: 0.5167 - val_loss: 0.6914 - val_accuracy: 0.5264\n","Epoch 13/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6890 - accuracy: 0.5226 - val_loss: 0.6909 - val_accuracy: 0.5309\n","Epoch 14/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6882 - accuracy: 0.5297 - val_loss: 0.6901 - val_accuracy: 0.5291\n","Epoch 15/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6883 - accuracy: 0.5272 - val_loss: 0.6908 - val_accuracy: 0.5226\n","Epoch 16/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6878 - accuracy: 0.5299 - val_loss: 0.6896 - val_accuracy: 0.5356\n","Epoch 17/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6872 - accuracy: 0.5294 - val_loss: 0.6892 - val_accuracy: 0.5340\n","Epoch 18/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6869 - accuracy: 0.5337 - val_loss: 0.6893 - val_accuracy: 0.5402\n","Epoch 19/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6867 - accuracy: 0.5330 - val_loss: 0.6892 - val_accuracy: 0.5352\n","Epoch 20/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6861 - accuracy: 0.5330 - val_loss: 0.6910 - val_accuracy: 0.5266\n","Epoch 21/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6862 - accuracy: 0.5343 - val_loss: 0.6884 - val_accuracy: 0.5361\n","Epoch 22/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6855 - accuracy: 0.5407 - val_loss: 0.6890 - val_accuracy: 0.5381\n","Epoch 23/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6851 - accuracy: 0.5375 - val_loss: 0.6892 - val_accuracy: 0.5321\n","Epoch 24/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6851 - accuracy: 0.5376 - val_loss: 0.6890 - val_accuracy: 0.5358\n","Epoch 25/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6853 - accuracy: 0.5393 - val_loss: 0.6888 - val_accuracy: 0.5390\n","Epoch 26/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6847 - accuracy: 0.5399 - val_loss: 0.6890 - val_accuracy: 0.5351\n","Epoch 27/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6841 - accuracy: 0.5438 - val_loss: 0.6907 - val_accuracy: 0.5301\n","Epoch 28/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6846 - accuracy: 0.5381 - val_loss: 0.6885 - val_accuracy: 0.5377\n","Epoch 29/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6845 - accuracy: 0.5399 - val_loss: 0.6883 - val_accuracy: 0.5407\n","Epoch 30/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6839 - accuracy: 0.5423 - val_loss: 0.6887 - val_accuracy: 0.5379\n","Epoch 31/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6836 - accuracy: 0.5460 - val_loss: 0.6894 - val_accuracy: 0.5401\n","Epoch 32/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6837 - accuracy: 0.5466 - val_loss: 0.6896 - val_accuracy: 0.5370\n","Epoch 33/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6835 - accuracy: 0.5401 - val_loss: 0.6889 - val_accuracy: 0.5389\n","Epoch 34/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6832 - accuracy: 0.5443 - val_loss: 0.6889 - val_accuracy: 0.5399\n","Epoch 35/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6841 - accuracy: 0.5469 - val_loss: 0.6890 - val_accuracy: 0.5363\n","Epoch 36/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6833 - accuracy: 0.5431 - val_loss: 0.6886 - val_accuracy: 0.5412\n","Epoch 37/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6829 - accuracy: 0.5440 - val_loss: 0.6888 - val_accuracy: 0.5396\n","Epoch 38/400\n","142/142 [==============================] - 16s 110ms/step - loss: 0.6831 - accuracy: 0.5460 - val_loss: 0.6899 - val_accuracy: 0.5363\n","Epoch 39/400\n","142/142 [==============================] - 16s 114ms/step - loss: 0.6831 - accuracy: 0.5499 - val_loss: 0.6893 - val_accuracy: 0.5387\n","Epoch 40/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6824 - accuracy: 0.5501 - val_loss: 0.6896 - val_accuracy: 0.5360\n","Epoch 41/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6829 - accuracy: 0.5438 - val_loss: 0.6893 - val_accuracy: 0.5353\n","Epoch 42/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6818 - accuracy: 0.5489 - val_loss: 0.6909 - val_accuracy: 0.5339\n","Epoch 43/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6824 - accuracy: 0.5498 - val_loss: 0.6895 - val_accuracy: 0.5409\n","Epoch 44/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6838 - accuracy: 0.5463 - val_loss: 0.6907 - val_accuracy: 0.5335\n","Epoch 45/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6832 - accuracy: 0.5450 - val_loss: 0.6922 - val_accuracy: 0.5331\n","Epoch 46/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6828 - accuracy: 0.5433 - val_loss: 0.6894 - val_accuracy: 0.5387\n","Epoch 47/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6816 - accuracy: 0.5473 - val_loss: 0.6896 - val_accuracy: 0.5375\n","Epoch 48/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6815 - accuracy: 0.5463 - val_loss: 0.6902 - val_accuracy: 0.5336\n","Epoch 49/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6818 - accuracy: 0.5493 - val_loss: 0.6898 - val_accuracy: 0.5333\n","Epoch 50/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6819 - accuracy: 0.5481 - val_loss: 0.6922 - val_accuracy: 0.5275\n","Epoch 51/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6815 - accuracy: 0.5486 - val_loss: 0.6912 - val_accuracy: 0.5351\n","Epoch 52/400\n","142/142 [==============================] - 16s 112ms/step - loss: 0.6820 - accuracy: 0.5523 - val_loss: 0.6905 - val_accuracy: 0.5319\n","Epoch 53/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6807 - accuracy: 0.5481 - val_loss: 0.6901 - val_accuracy: 0.5314\n","Epoch 54/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6818 - accuracy: 0.5439 - val_loss: 0.6914 - val_accuracy: 0.5379\n","Epoch 55/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6813 - accuracy: 0.5482 - val_loss: 0.6903 - val_accuracy: 0.5267\n","Epoch 56/400\n","142/142 [==============================] - 16s 111ms/step - loss: 0.6814 - accuracy: 0.5473 - val_loss: 0.6903 - val_accuracy: 0.5330\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["   train_acc  train_f1  tune_acc   tune_f1  test_acc   test_f1\n","0   0.542364  0.542234  0.540139  0.537295  0.526994  0.525064\n","1   0.534762  0.533756  0.541808  0.541606  0.519326  0.516555\n","2   0.547543  0.546179  0.541286  0.541223  0.529185  0.527102\n","3   0.544623  0.543158  0.540347  0.540219  0.527046  0.521535\n","4   0.545670  0.544153  0.541234  0.540168  0.527411  0.519087\n","5   0.550463  0.546409  0.541182  0.540799  0.526420  0.502263\n","Attempt 7/12\n","Epoch 1/400\n","142/142 [==============================] - 18s 103ms/step - loss: 0.6951 - accuracy: 0.4976 - val_loss: 0.6931 - val_accuracy: 0.5057\n","Epoch 2/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6941 - accuracy: 0.5003 - val_loss: 0.6933 - val_accuracy: 0.4914\n","Epoch 3/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6936 - accuracy: 0.5033 - val_loss: 0.6932 - val_accuracy: 0.4947\n","Epoch 4/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6934 - accuracy: 0.5003 - val_loss: 0.6931 - val_accuracy: 0.5036\n","Epoch 5/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6932 - accuracy: 0.5104 - val_loss: 0.6928 - val_accuracy: 0.5110\n","Epoch 6/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6933 - accuracy: 0.5074 - val_loss: 0.6927 - val_accuracy: 0.5112\n","Epoch 7/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6928 - accuracy: 0.5082 - val_loss: 0.6930 - val_accuracy: 0.5093\n","Epoch 8/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6927 - accuracy: 0.5078 - val_loss: 0.6928 - val_accuracy: 0.5169\n","Epoch 9/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6919 - accuracy: 0.5127 - val_loss: 0.6931 - val_accuracy: 0.4998\n","Epoch 10/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6930 - accuracy: 0.5084 - val_loss: 0.6927 - val_accuracy: 0.5095\n","Epoch 11/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6928 - accuracy: 0.5029 - val_loss: 0.6927 - val_accuracy: 0.5135\n","Epoch 12/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6919 - accuracy: 0.5111 - val_loss: 0.6928 - val_accuracy: 0.5062\n","Epoch 13/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6913 - accuracy: 0.5056 - val_loss: 0.6929 - val_accuracy: 0.5087\n","Epoch 14/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6909 - accuracy: 0.5099 - val_loss: 0.6927 - val_accuracy: 0.5030\n","Epoch 15/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6900 - accuracy: 0.5120 - val_loss: 0.6926 - val_accuracy: 0.5181\n","Epoch 16/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6899 - accuracy: 0.5157 - val_loss: 0.6927 - val_accuracy: 0.5181\n","Epoch 17/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6899 - accuracy: 0.5104 - val_loss: 0.6924 - val_accuracy: 0.5086\n","Epoch 18/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6894 - accuracy: 0.5183 - val_loss: 0.6930 - val_accuracy: 0.5014\n","Epoch 19/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6893 - accuracy: 0.5165 - val_loss: 0.6927 - val_accuracy: 0.5086\n","Epoch 20/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6903 - accuracy: 0.5171 - val_loss: 0.6922 - val_accuracy: 0.5177\n","Epoch 21/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6893 - accuracy: 0.5210 - val_loss: 0.6915 - val_accuracy: 0.5252\n","Epoch 22/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6884 - accuracy: 0.5225 - val_loss: 0.6915 - val_accuracy: 0.5270\n","Epoch 23/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6889 - accuracy: 0.5167 - val_loss: 0.6919 - val_accuracy: 0.5157\n","Epoch 24/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6885 - accuracy: 0.5213 - val_loss: 0.6917 - val_accuracy: 0.5257\n","Epoch 25/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6887 - accuracy: 0.5234 - val_loss: 0.6912 - val_accuracy: 0.5248\n","Epoch 26/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6878 - accuracy: 0.5264 - val_loss: 0.6912 - val_accuracy: 0.5157\n","Epoch 27/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6888 - accuracy: 0.5181 - val_loss: 0.6911 - val_accuracy: 0.5284\n","Epoch 28/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6884 - accuracy: 0.5207 - val_loss: 0.6914 - val_accuracy: 0.5242\n","Epoch 29/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6875 - accuracy: 0.5218 - val_loss: 0.6908 - val_accuracy: 0.5308\n","Epoch 30/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6876 - accuracy: 0.5268 - val_loss: 0.6907 - val_accuracy: 0.5325\n","Epoch 31/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6874 - accuracy: 0.5273 - val_loss: 0.6908 - val_accuracy: 0.5257\n","Epoch 32/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6874 - accuracy: 0.5289 - val_loss: 0.6908 - val_accuracy: 0.5283\n","Epoch 33/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6873 - accuracy: 0.5309 - val_loss: 0.6907 - val_accuracy: 0.5338\n","Epoch 34/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6871 - accuracy: 0.5324 - val_loss: 0.6897 - val_accuracy: 0.5376\n","Epoch 35/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6869 - accuracy: 0.5290 - val_loss: 0.6897 - val_accuracy: 0.5396\n","Epoch 36/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6861 - accuracy: 0.5385 - val_loss: 0.6895 - val_accuracy: 0.5387\n","Epoch 37/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6860 - accuracy: 0.5374 - val_loss: 0.6904 - val_accuracy: 0.5306\n","Epoch 38/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6854 - accuracy: 0.5365 - val_loss: 0.6898 - val_accuracy: 0.5350\n","Epoch 39/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6853 - accuracy: 0.5343 - val_loss: 0.6891 - val_accuracy: 0.5378\n","Epoch 40/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6855 - accuracy: 0.5359 - val_loss: 0.6935 - val_accuracy: 0.5300\n","Epoch 41/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6848 - accuracy: 0.5430 - val_loss: 0.6900 - val_accuracy: 0.5350\n","Epoch 42/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6849 - accuracy: 0.5413 - val_loss: 0.6915 - val_accuracy: 0.5314\n","Epoch 43/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6852 - accuracy: 0.5428 - val_loss: 0.6895 - val_accuracy: 0.5384\n","Epoch 44/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6857 - accuracy: 0.5375 - val_loss: 0.6899 - val_accuracy: 0.5284\n","Epoch 45/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6851 - accuracy: 0.5409 - val_loss: 0.6909 - val_accuracy: 0.5245\n","Epoch 46/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6846 - accuracy: 0.5394 - val_loss: 0.6896 - val_accuracy: 0.5362\n","Epoch 47/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6846 - accuracy: 0.5408 - val_loss: 0.6891 - val_accuracy: 0.5362\n","Epoch 48/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6848 - accuracy: 0.5373 - val_loss: 0.6886 - val_accuracy: 0.5370\n","Epoch 49/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6841 - accuracy: 0.5408 - val_loss: 0.6888 - val_accuracy: 0.5394\n","Epoch 50/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6836 - accuracy: 0.5462 - val_loss: 0.6887 - val_accuracy: 0.5381\n","Epoch 51/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6834 - accuracy: 0.5452 - val_loss: 0.6892 - val_accuracy: 0.5399\n","Epoch 52/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6833 - accuracy: 0.5440 - val_loss: 0.6926 - val_accuracy: 0.5312\n","Epoch 53/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6840 - accuracy: 0.5422 - val_loss: 0.6890 - val_accuracy: 0.5375\n","Epoch 54/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6833 - accuracy: 0.5404 - val_loss: 0.6891 - val_accuracy: 0.5365\n","Epoch 55/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6852 - accuracy: 0.5414 - val_loss: 0.6898 - val_accuracy: 0.5354\n","Epoch 56/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6832 - accuracy: 0.5436 - val_loss: 0.6890 - val_accuracy: 0.5369\n","Epoch 57/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6832 - accuracy: 0.5468 - val_loss: 0.6900 - val_accuracy: 0.5372\n","Epoch 58/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6837 - accuracy: 0.5430 - val_loss: 0.6890 - val_accuracy: 0.5373\n","Epoch 59/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6828 - accuracy: 0.5458 - val_loss: 0.6903 - val_accuracy: 0.5355\n","Epoch 60/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6827 - accuracy: 0.5453 - val_loss: 0.6895 - val_accuracy: 0.5342\n","Epoch 61/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6820 - accuracy: 0.5463 - val_loss: 0.6936 - val_accuracy: 0.5357\n","Epoch 62/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6828 - accuracy: 0.5473 - val_loss: 0.6890 - val_accuracy: 0.5400\n","Epoch 63/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6827 - accuracy: 0.5442 - val_loss: 0.6889 - val_accuracy: 0.5376\n","Epoch 64/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6828 - accuracy: 0.5464 - val_loss: 0.6897 - val_accuracy: 0.5379\n","Epoch 65/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6824 - accuracy: 0.5501 - val_loss: 0.6909 - val_accuracy: 0.5396\n","Epoch 66/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6842 - accuracy: 0.5425 - val_loss: 0.6894 - val_accuracy: 0.5351\n","Epoch 67/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6815 - accuracy: 0.5475 - val_loss: 0.6904 - val_accuracy: 0.5332\n","Epoch 68/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6830 - accuracy: 0.5429 - val_loss: 0.6891 - val_accuracy: 0.5359\n","Epoch 69/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6817 - accuracy: 0.5439 - val_loss: 0.6896 - val_accuracy: 0.5362\n","Epoch 70/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6822 - accuracy: 0.5470 - val_loss: 0.6902 - val_accuracy: 0.5367\n","Epoch 71/400\n","142/142 [==============================] - 14s 101ms/step - loss: 0.6815 - accuracy: 0.5478 - val_loss: 0.6897 - val_accuracy: 0.5354\n","Epoch 72/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6817 - accuracy: 0.5509 - val_loss: 0.6910 - val_accuracy: 0.5379\n","Epoch 73/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6816 - accuracy: 0.5474 - val_loss: 0.6893 - val_accuracy: 0.5391\n","Epoch 74/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6812 - accuracy: 0.5491 - val_loss: 0.6901 - val_accuracy: 0.5348\n","Epoch 75/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6814 - accuracy: 0.5530 - val_loss: 0.6893 - val_accuracy: 0.5383\n","Epoch 76/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6813 - accuracy: 0.5516 - val_loss: 0.6900 - val_accuracy: 0.5346\n","Epoch 77/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6809 - accuracy: 0.5530 - val_loss: 0.6900 - val_accuracy: 0.5338\n","Epoch 78/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6802 - accuracy: 0.5506 - val_loss: 0.6919 - val_accuracy: 0.5371\n","Epoch 79/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6809 - accuracy: 0.5520 - val_loss: 0.6917 - val_accuracy: 0.5343\n","Epoch 80/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6808 - accuracy: 0.5515 - val_loss: 0.6903 - val_accuracy: 0.5357\n","Epoch 81/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6805 - accuracy: 0.5496 - val_loss: 0.6923 - val_accuracy: 0.5343\n","Epoch 82/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6869 - accuracy: 0.5420 - val_loss: 0.6904 - val_accuracy: 0.5367\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["   train_acc  train_f1  tune_acc   tune_f1  test_acc   test_f1\n","0   0.542364  0.542234  0.540139  0.537295  0.526994  0.525064\n","1   0.534762  0.533756  0.541808  0.541606  0.519326  0.516555\n","2   0.547543  0.546179  0.541286  0.541223  0.529185  0.527102\n","3   0.544623  0.543158  0.540347  0.540219  0.527046  0.521535\n","4   0.545670  0.544153  0.541234  0.540168  0.527411  0.519087\n","5   0.550463  0.546409  0.541182  0.540799  0.526420  0.502263\n","6   0.546717  0.546565  0.540034  0.532382  0.522351  0.497278\n","Attempt 8/12\n","Epoch 1/400\n","142/142 [==============================] - 18s 102ms/step - loss: 0.6954 - accuracy: 0.4931 - val_loss: 0.6929 - val_accuracy: 0.5100\n","Epoch 2/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6939 - accuracy: 0.5023 - val_loss: 0.6931 - val_accuracy: 0.5002\n","Epoch 3/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6935 - accuracy: 0.5008 - val_loss: 0.6929 - val_accuracy: 0.5103\n","Epoch 4/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6934 - accuracy: 0.5071 - val_loss: 0.6933 - val_accuracy: 0.4919\n","Epoch 5/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6931 - accuracy: 0.5095 - val_loss: 0.6932 - val_accuracy: 0.4974\n","Epoch 6/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6928 - accuracy: 0.5066 - val_loss: 0.6929 - val_accuracy: 0.5172\n","Epoch 7/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6927 - accuracy: 0.5017 - val_loss: 0.6932 - val_accuracy: 0.4968\n","Epoch 8/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6910 - accuracy: 0.5118 - val_loss: 0.6934 - val_accuracy: 0.4924\n","Epoch 9/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6915 - accuracy: 0.5080 - val_loss: 0.6928 - val_accuracy: 0.5178\n","Epoch 10/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6905 - accuracy: 0.5129 - val_loss: 0.6935 - val_accuracy: 0.4922\n","Epoch 11/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6906 - accuracy: 0.5132 - val_loss: 0.6933 - val_accuracy: 0.4926\n","Epoch 12/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6904 - accuracy: 0.5101 - val_loss: 0.6929 - val_accuracy: 0.5050\n","Epoch 13/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6899 - accuracy: 0.5113 - val_loss: 0.6926 - val_accuracy: 0.5038\n","Epoch 14/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6896 - accuracy: 0.5149 - val_loss: 0.6922 - val_accuracy: 0.5104\n","Epoch 15/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6897 - accuracy: 0.5136 - val_loss: 0.6920 - val_accuracy: 0.5245\n","Epoch 16/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6893 - accuracy: 0.5155 - val_loss: 0.6919 - val_accuracy: 0.5167\n","Epoch 17/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6891 - accuracy: 0.5125 - val_loss: 0.6918 - val_accuracy: 0.5266\n","Epoch 18/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6894 - accuracy: 0.5081 - val_loss: 0.6917 - val_accuracy: 0.5226\n","Epoch 19/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6890 - accuracy: 0.5188 - val_loss: 0.6916 - val_accuracy: 0.5201\n","Epoch 20/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6884 - accuracy: 0.5194 - val_loss: 0.6918 - val_accuracy: 0.5198\n","Epoch 21/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6886 - accuracy: 0.5167 - val_loss: 0.6914 - val_accuracy: 0.5265\n","Epoch 22/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6918 - accuracy: 0.5195 - val_loss: 0.6915 - val_accuracy: 0.5271\n","Epoch 23/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6894 - accuracy: 0.5225 - val_loss: 0.6910 - val_accuracy: 0.5259\n","Epoch 24/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6887 - accuracy: 0.5246 - val_loss: 0.6910 - val_accuracy: 0.5308\n","Epoch 25/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6878 - accuracy: 0.5250 - val_loss: 0.6910 - val_accuracy: 0.5216\n","Epoch 26/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6881 - accuracy: 0.5224 - val_loss: 0.6909 - val_accuracy: 0.5244\n","Epoch 27/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6875 - accuracy: 0.5245 - val_loss: 0.6900 - val_accuracy: 0.5345\n","Epoch 28/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6869 - accuracy: 0.5304 - val_loss: 0.6895 - val_accuracy: 0.5391\n","Epoch 29/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6872 - accuracy: 0.5311 - val_loss: 0.6893 - val_accuracy: 0.5365\n","Epoch 30/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6864 - accuracy: 0.5301 - val_loss: 0.6894 - val_accuracy: 0.5390\n","Epoch 31/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6857 - accuracy: 0.5368 - val_loss: 0.6888 - val_accuracy: 0.5376\n","Epoch 32/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6860 - accuracy: 0.5355 - val_loss: 0.6889 - val_accuracy: 0.5412\n","Epoch 33/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6858 - accuracy: 0.5373 - val_loss: 0.6894 - val_accuracy: 0.5381\n","Epoch 34/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6857 - accuracy: 0.5361 - val_loss: 0.6894 - val_accuracy: 0.5339\n","Epoch 35/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6848 - accuracy: 0.5381 - val_loss: 0.6891 - val_accuracy: 0.5340\n","Epoch 36/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6852 - accuracy: 0.5385 - val_loss: 0.6891 - val_accuracy: 0.5370\n","Epoch 37/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6841 - accuracy: 0.5414 - val_loss: 0.6890 - val_accuracy: 0.5377\n","Epoch 38/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6847 - accuracy: 0.5458 - val_loss: 0.6891 - val_accuracy: 0.5352\n","Epoch 39/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6841 - accuracy: 0.5394 - val_loss: 0.6886 - val_accuracy: 0.5410\n","Epoch 40/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6842 - accuracy: 0.5416 - val_loss: 0.6889 - val_accuracy: 0.5372\n","Epoch 41/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6843 - accuracy: 0.5418 - val_loss: 0.6893 - val_accuracy: 0.5383\n","Epoch 42/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6844 - accuracy: 0.5441 - val_loss: 0.6884 - val_accuracy: 0.5398\n","Epoch 43/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6836 - accuracy: 0.5456 - val_loss: 0.6887 - val_accuracy: 0.5365\n","Epoch 44/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6837 - accuracy: 0.5457 - val_loss: 0.6902 - val_accuracy: 0.5379\n","Epoch 45/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6843 - accuracy: 0.5450 - val_loss: 0.6893 - val_accuracy: 0.5345\n","Epoch 46/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6833 - accuracy: 0.5463 - val_loss: 0.6888 - val_accuracy: 0.5396\n","Epoch 47/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6833 - accuracy: 0.5444 - val_loss: 0.6890 - val_accuracy: 0.5367\n","Epoch 48/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6832 - accuracy: 0.5469 - val_loss: 0.6907 - val_accuracy: 0.5349\n","Epoch 49/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6834 - accuracy: 0.5418 - val_loss: 0.6890 - val_accuracy: 0.5375\n","Epoch 50/400\n","142/142 [==============================] - 14s 100ms/step - loss: 0.6829 - accuracy: 0.5432 - val_loss: 0.6929 - val_accuracy: 0.5294\n","Epoch 51/400\n","142/142 [==============================] - 14s 101ms/step - loss: 0.6825 - accuracy: 0.5426 - val_loss: 0.6894 - val_accuracy: 0.5395\n","Epoch 52/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6829 - accuracy: 0.5439 - val_loss: 0.6901 - val_accuracy: 0.5343\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["   train_acc  train_f1  tune_acc   tune_f1  test_acc   test_f1\n","0   0.542364  0.542234  0.540139  0.537295  0.526994  0.525064\n","1   0.534762  0.533756  0.541808  0.541606  0.519326  0.516555\n","2   0.547543  0.546179  0.541286  0.541223  0.529185  0.527102\n","3   0.544623  0.543158  0.540347  0.540219  0.527046  0.521535\n","4   0.545670  0.544153  0.541234  0.540168  0.527411  0.519087\n","5   0.550463  0.546409  0.541182  0.540799  0.526420  0.502263\n","6   0.546717  0.546565  0.540034  0.532382  0.522351  0.497278\n","7   0.545615  0.545592  0.541234  0.534021  0.532680  0.532576\n","Attempt 9/12\n","Epoch 1/400\n","142/142 [==============================] - 18s 102ms/step - loss: 0.6944 - accuracy: 0.5072 - val_loss: 0.6935 - val_accuracy: 0.4917\n","Epoch 2/400\n","142/142 [==============================] - 14s 96ms/step - loss: 0.6935 - accuracy: 0.5036 - val_loss: 0.6929 - val_accuracy: 0.5098\n","Epoch 3/400\n","142/142 [==============================] - 14s 96ms/step - loss: 0.6933 - accuracy: 0.5100 - val_loss: 0.6935 - val_accuracy: 0.4974\n","Epoch 4/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6935 - accuracy: 0.4996 - val_loss: 0.6932 - val_accuracy: 0.4995\n","Epoch 5/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6925 - accuracy: 0.5080 - val_loss: 0.6928 - val_accuracy: 0.5089\n","Epoch 6/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6922 - accuracy: 0.5044 - val_loss: 0.6928 - val_accuracy: 0.5089\n","Epoch 7/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6916 - accuracy: 0.5058 - val_loss: 0.6930 - val_accuracy: 0.4969\n","Epoch 8/400\n","142/142 [==============================] - 14s 96ms/step - loss: 0.6910 - accuracy: 0.5052 - val_loss: 0.6935 - val_accuracy: 0.4924\n","Epoch 9/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6903 - accuracy: 0.5102 - val_loss: 0.6930 - val_accuracy: 0.5043\n","Epoch 10/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6901 - accuracy: 0.5052 - val_loss: 0.6928 - val_accuracy: 0.5173\n","Epoch 11/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6901 - accuracy: 0.5111 - val_loss: 0.6925 - val_accuracy: 0.5088\n","Epoch 12/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6902 - accuracy: 0.5055 - val_loss: 0.6925 - val_accuracy: 0.5125\n","Epoch 13/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6894 - accuracy: 0.5142 - val_loss: 0.6937 - val_accuracy: 0.5177\n","Epoch 14/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6894 - accuracy: 0.5137 - val_loss: 0.6924 - val_accuracy: 0.5226\n","Epoch 15/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6896 - accuracy: 0.5162 - val_loss: 0.6926 - val_accuracy: 0.5072\n","Epoch 16/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6895 - accuracy: 0.5138 - val_loss: 0.6924 - val_accuracy: 0.5102\n","Epoch 17/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6907 - accuracy: 0.5106 - val_loss: 0.6927 - val_accuracy: 0.5226\n","Epoch 18/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6908 - accuracy: 0.5184 - val_loss: 0.6923 - val_accuracy: 0.5101\n","Epoch 19/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6891 - accuracy: 0.5177 - val_loss: 0.6920 - val_accuracy: 0.5228\n","Epoch 20/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6892 - accuracy: 0.5177 - val_loss: 0.6919 - val_accuracy: 0.5242\n","Epoch 21/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6889 - accuracy: 0.5177 - val_loss: 0.6917 - val_accuracy: 0.5210\n","Epoch 22/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6890 - accuracy: 0.5159 - val_loss: 0.6924 - val_accuracy: 0.5060\n","Epoch 23/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6886 - accuracy: 0.5155 - val_loss: 0.6916 - val_accuracy: 0.5266\n","Epoch 24/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6913 - accuracy: 0.5166 - val_loss: 0.6918 - val_accuracy: 0.5239\n","Epoch 25/400\n","142/142 [==============================] - 14s 96ms/step - loss: 0.6890 - accuracy: 0.5163 - val_loss: 0.6918 - val_accuracy: 0.5254\n","Epoch 26/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6880 - accuracy: 0.5230 - val_loss: 0.6912 - val_accuracy: 0.5206\n","Epoch 27/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6886 - accuracy: 0.5201 - val_loss: 0.6911 - val_accuracy: 0.5282\n","Epoch 28/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6875 - accuracy: 0.5210 - val_loss: 0.6918 - val_accuracy: 0.5189\n","Epoch 29/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6881 - accuracy: 0.5231 - val_loss: 0.6911 - val_accuracy: 0.5300\n","Epoch 30/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6873 - accuracy: 0.5286 - val_loss: 0.6903 - val_accuracy: 0.5284\n","Epoch 31/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6872 - accuracy: 0.5296 - val_loss: 0.6904 - val_accuracy: 0.5292\n","Epoch 32/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6872 - accuracy: 0.5268 - val_loss: 0.6901 - val_accuracy: 0.5347\n","Epoch 33/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6865 - accuracy: 0.5347 - val_loss: 0.6899 - val_accuracy: 0.5365\n","Epoch 34/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6869 - accuracy: 0.5283 - val_loss: 0.6897 - val_accuracy: 0.5360\n","Epoch 35/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6861 - accuracy: 0.5336 - val_loss: 0.6905 - val_accuracy: 0.5325\n","Epoch 36/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6862 - accuracy: 0.5325 - val_loss: 0.6900 - val_accuracy: 0.5306\n","Epoch 37/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6858 - accuracy: 0.5355 - val_loss: 0.6888 - val_accuracy: 0.5387\n","Epoch 38/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6858 - accuracy: 0.5377 - val_loss: 0.6890 - val_accuracy: 0.5373\n","Epoch 39/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6855 - accuracy: 0.5380 - val_loss: 0.6888 - val_accuracy: 0.5365\n","Epoch 40/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6854 - accuracy: 0.5347 - val_loss: 0.6955 - val_accuracy: 0.5198\n","Epoch 41/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6848 - accuracy: 0.5388 - val_loss: 0.6889 - val_accuracy: 0.5359\n","Epoch 42/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6845 - accuracy: 0.5392 - val_loss: 0.6888 - val_accuracy: 0.5381\n","Epoch 43/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6852 - accuracy: 0.5418 - val_loss: 0.6886 - val_accuracy: 0.5371\n","Epoch 44/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6844 - accuracy: 0.5410 - val_loss: 0.6904 - val_accuracy: 0.5313\n","Epoch 45/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6840 - accuracy: 0.5424 - val_loss: 0.6891 - val_accuracy: 0.5374\n","Epoch 46/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6846 - accuracy: 0.5374 - val_loss: 0.6890 - val_accuracy: 0.5372\n","Epoch 47/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6836 - accuracy: 0.5437 - val_loss: 0.6895 - val_accuracy: 0.5353\n","Epoch 48/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6843 - accuracy: 0.5413 - val_loss: 0.6889 - val_accuracy: 0.5367\n","Epoch 49/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6832 - accuracy: 0.5465 - val_loss: 0.6892 - val_accuracy: 0.5304\n","Epoch 50/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6838 - accuracy: 0.5417 - val_loss: 0.6893 - val_accuracy: 0.5359\n","Epoch 51/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6832 - accuracy: 0.5472 - val_loss: 0.6889 - val_accuracy: 0.5371\n","Epoch 52/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6831 - accuracy: 0.5426 - val_loss: 0.6885 - val_accuracy: 0.5393\n","Epoch 53/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6831 - accuracy: 0.5439 - val_loss: 0.6902 - val_accuracy: 0.5359\n","Epoch 54/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6830 - accuracy: 0.5458 - val_loss: 0.6890 - val_accuracy: 0.5380\n","Epoch 55/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6827 - accuracy: 0.5468 - val_loss: 0.6912 - val_accuracy: 0.5349\n","Epoch 56/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6825 - accuracy: 0.5475 - val_loss: 0.6895 - val_accuracy: 0.5325\n","Epoch 57/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6828 - accuracy: 0.5469 - val_loss: 0.6891 - val_accuracy: 0.5377\n","Epoch 58/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6823 - accuracy: 0.5436 - val_loss: 0.6890 - val_accuracy: 0.5349\n","Epoch 59/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6826 - accuracy: 0.5440 - val_loss: 0.6887 - val_accuracy: 0.5363\n","Epoch 60/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6819 - accuracy: 0.5481 - val_loss: 0.6893 - val_accuracy: 0.5342\n","Epoch 61/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6825 - accuracy: 0.5435 - val_loss: 0.6901 - val_accuracy: 0.5362\n","Epoch 62/400\n","142/142 [==============================] - 14s 97ms/step - loss: 0.6822 - accuracy: 0.5472 - val_loss: 0.6900 - val_accuracy: 0.5378\n","Epoch 63/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6810 - accuracy: 0.5497 - val_loss: 0.6898 - val_accuracy: 0.5360\n","Epoch 64/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6813 - accuracy: 0.5491 - val_loss: 0.6893 - val_accuracy: 0.5403\n","Epoch 65/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6821 - accuracy: 0.5490 - val_loss: 0.6914 - val_accuracy: 0.5350\n","Epoch 66/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6807 - accuracy: 0.5511 - val_loss: 0.6906 - val_accuracy: 0.5360\n","Epoch 67/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6812 - accuracy: 0.5466 - val_loss: 0.6904 - val_accuracy: 0.5316\n","Epoch 68/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6814 - accuracy: 0.5510 - val_loss: 0.6904 - val_accuracy: 0.5359\n","Epoch 69/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6808 - accuracy: 0.5485 - val_loss: 0.6930 - val_accuracy: 0.5340\n","Epoch 70/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6815 - accuracy: 0.5510 - val_loss: 0.6899 - val_accuracy: 0.5339\n","Epoch 71/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6807 - accuracy: 0.5492 - val_loss: 0.6920 - val_accuracy: 0.5335\n","Epoch 72/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6814 - accuracy: 0.5478 - val_loss: 0.6918 - val_accuracy: 0.5341\n","Epoch 73/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6811 - accuracy: 0.5450 - val_loss: 0.6919 - val_accuracy: 0.5330\n","Epoch 74/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6808 - accuracy: 0.5489 - val_loss: 0.6907 - val_accuracy: 0.5370\n","Epoch 75/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6811 - accuracy: 0.5499 - val_loss: 0.6917 - val_accuracy: 0.5328\n","Epoch 76/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6799 - accuracy: 0.5535 - val_loss: 0.6902 - val_accuracy: 0.5350\n","Epoch 77/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6806 - accuracy: 0.5508 - val_loss: 0.6912 - val_accuracy: 0.5366\n","Epoch 78/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6803 - accuracy: 0.5497 - val_loss: 0.6920 - val_accuracy: 0.5304\n","Epoch 79/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6794 - accuracy: 0.5587 - val_loss: 0.6915 - val_accuracy: 0.5346\n","Epoch 80/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6797 - accuracy: 0.5507 - val_loss: 0.6936 - val_accuracy: 0.5261\n","Epoch 81/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6796 - accuracy: 0.5540 - val_loss: 0.6933 - val_accuracy: 0.5285\n","Epoch 82/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6801 - accuracy: 0.5507 - val_loss: 0.6903 - val_accuracy: 0.5387\n","Epoch 83/400\n","142/142 [==============================] - 14s 98ms/step - loss: 0.6796 - accuracy: 0.5518 - val_loss: 0.6927 - val_accuracy: 0.5311\n","Epoch 84/400\n","142/142 [==============================] - 14s 99ms/step - loss: 0.6799 - accuracy: 0.5507 - val_loss: 0.6911 - val_accuracy: 0.5314\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["   train_acc  train_f1  tune_acc   tune_f1  test_acc   test_f1\n","0   0.542364  0.542234  0.540139  0.537295  0.526994  0.525064\n","1   0.534762  0.533756  0.541808  0.541606  0.519326  0.516555\n","2   0.547543  0.546179  0.541286  0.541223  0.529185  0.527102\n","3   0.544623  0.543158  0.540347  0.540219  0.527046  0.521535\n","4   0.545670  0.544153  0.541234  0.540168  0.527411  0.519087\n","5   0.550463  0.546409  0.541182  0.540799  0.526420  0.502263\n","6   0.546717  0.546565  0.540034  0.532382  0.522351  0.497278\n","7   0.545615  0.545592  0.541234  0.534021  0.532680  0.532576\n","8   0.551730  0.546371  0.540347  0.540006  0.523760  0.506559\n","Attempt 10/12\n","Epoch 1/400\n","142/142 [==============================] - 41s 264ms/step - loss: 0.6949 - accuracy: 0.5005 - val_loss: 0.6937 - val_accuracy: 0.5089\n","Epoch 2/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6941 - accuracy: 0.5039 - val_loss: 0.6934 - val_accuracy: 0.4920\n","Epoch 3/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6934 - accuracy: 0.5041 - val_loss: 0.6942 - val_accuracy: 0.5088\n","Epoch 4/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6936 - accuracy: 0.5042 - val_loss: 0.6930 - val_accuracy: 0.5035\n","Epoch 5/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6929 - accuracy: 0.5055 - val_loss: 0.6933 - val_accuracy: 0.5089\n","Epoch 6/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6938 - accuracy: 0.4938 - val_loss: 0.6943 - val_accuracy: 0.4911\n","Epoch 7/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6935 - accuracy: 0.4971 - val_loss: 0.6931 - val_accuracy: 0.5033\n","Epoch 8/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6927 - accuracy: 0.5115 - val_loss: 0.6930 - val_accuracy: 0.5137\n","Epoch 9/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6910 - accuracy: 0.5076 - val_loss: 0.6928 - val_accuracy: 0.5128\n","Epoch 10/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6911 - accuracy: 0.5062 - val_loss: 0.6931 - val_accuracy: 0.4950\n","Epoch 11/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6917 - accuracy: 0.5117 - val_loss: 0.6925 - val_accuracy: 0.5177\n","Epoch 12/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6901 - accuracy: 0.5126 - val_loss: 0.6923 - val_accuracy: 0.5189\n","Epoch 13/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6898 - accuracy: 0.5151 - val_loss: 0.6930 - val_accuracy: 0.4959\n","Epoch 14/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6899 - accuracy: 0.5121 - val_loss: 0.6924 - val_accuracy: 0.5127\n","Epoch 15/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6916 - accuracy: 0.5125 - val_loss: 0.6925 - val_accuracy: 0.5224\n","Epoch 16/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6928 - accuracy: 0.5109 - val_loss: 0.6925 - val_accuracy: 0.5114\n","Epoch 17/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6923 - accuracy: 0.5047 - val_loss: 0.6926 - val_accuracy: 0.5186\n","Epoch 18/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6908 - accuracy: 0.5134 - val_loss: 0.6929 - val_accuracy: 0.5114\n","Epoch 19/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6895 - accuracy: 0.5172 - val_loss: 0.6921 - val_accuracy: 0.5242\n","Epoch 20/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6892 - accuracy: 0.5128 - val_loss: 0.6916 - val_accuracy: 0.5246\n","Epoch 21/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6883 - accuracy: 0.5196 - val_loss: 0.6915 - val_accuracy: 0.5236\n","Epoch 22/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6886 - accuracy: 0.5217 - val_loss: 0.6918 - val_accuracy: 0.5263\n","Epoch 23/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6912 - accuracy: 0.5212 - val_loss: 0.6921 - val_accuracy: 0.5107\n","Epoch 24/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6921 - accuracy: 0.5202 - val_loss: 0.6924 - val_accuracy: 0.5107\n","Epoch 25/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6892 - accuracy: 0.5215 - val_loss: 0.6915 - val_accuracy: 0.5262\n","Epoch 26/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6881 - accuracy: 0.5234 - val_loss: 0.6911 - val_accuracy: 0.5241\n","Epoch 27/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6877 - accuracy: 0.5261 - val_loss: 0.6921 - val_accuracy: 0.5144\n","Epoch 28/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6882 - accuracy: 0.5231 - val_loss: 0.6908 - val_accuracy: 0.5295\n","Epoch 29/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6871 - accuracy: 0.5277 - val_loss: 0.6925 - val_accuracy: 0.5318\n","Epoch 30/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6887 - accuracy: 0.5233 - val_loss: 0.6910 - val_accuracy: 0.5238\n","Epoch 31/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6871 - accuracy: 0.5304 - val_loss: 0.6898 - val_accuracy: 0.5384\n","Epoch 32/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6866 - accuracy: 0.5347 - val_loss: 0.6901 - val_accuracy: 0.5351\n","Epoch 33/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6862 - accuracy: 0.5371 - val_loss: 0.6890 - val_accuracy: 0.5368\n","Epoch 34/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6858 - accuracy: 0.5366 - val_loss: 0.6892 - val_accuracy: 0.5335\n","Epoch 35/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6847 - accuracy: 0.5418 - val_loss: 0.6909 - val_accuracy: 0.5231\n","Epoch 36/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6857 - accuracy: 0.5363 - val_loss: 0.6891 - val_accuracy: 0.5366\n","Epoch 37/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6853 - accuracy: 0.5371 - val_loss: 0.6896 - val_accuracy: 0.5405\n","Epoch 38/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6846 - accuracy: 0.5408 - val_loss: 0.6889 - val_accuracy: 0.5375\n","Epoch 39/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6853 - accuracy: 0.5364 - val_loss: 0.6891 - val_accuracy: 0.5364\n","Epoch 40/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6847 - accuracy: 0.5392 - val_loss: 0.6899 - val_accuracy: 0.5352\n","Epoch 41/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6849 - accuracy: 0.5385 - val_loss: 0.6897 - val_accuracy: 0.5328\n","Epoch 42/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6844 - accuracy: 0.5383 - val_loss: 0.6888 - val_accuracy: 0.5393\n","Epoch 43/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6844 - accuracy: 0.5427 - val_loss: 0.6886 - val_accuracy: 0.5387\n","Epoch 44/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6841 - accuracy: 0.5414 - val_loss: 0.6890 - val_accuracy: 0.5379\n","Epoch 45/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6839 - accuracy: 0.5380 - val_loss: 0.6889 - val_accuracy: 0.5398\n","Epoch 46/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6840 - accuracy: 0.5406 - val_loss: 0.6896 - val_accuracy: 0.5381\n","Epoch 47/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6844 - accuracy: 0.5387 - val_loss: 0.6892 - val_accuracy: 0.5379\n","Epoch 48/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6873 - accuracy: 0.5382 - val_loss: 0.6890 - val_accuracy: 0.5355\n","Epoch 49/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6834 - accuracy: 0.5439 - val_loss: 0.6929 - val_accuracy: 0.5351\n","Epoch 50/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6836 - accuracy: 0.5432 - val_loss: 0.6897 - val_accuracy: 0.5386\n","Epoch 51/400\n","142/142 [==============================] - 37s 263ms/step - loss: 0.6829 - accuracy: 0.5440 - val_loss: 0.6889 - val_accuracy: 0.5373\n","Epoch 52/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6830 - accuracy: 0.5483 - val_loss: 0.6898 - val_accuracy: 0.5360\n","Epoch 53/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6822 - accuracy: 0.5468 - val_loss: 0.6888 - val_accuracy: 0.5382\n","Epoch 54/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6825 - accuracy: 0.5459 - val_loss: 0.6898 - val_accuracy: 0.5381\n","Epoch 55/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6830 - accuracy: 0.5455 - val_loss: 0.6895 - val_accuracy: 0.5351\n","Epoch 56/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6827 - accuracy: 0.5490 - val_loss: 0.6912 - val_accuracy: 0.5337\n","Epoch 57/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6826 - accuracy: 0.5443 - val_loss: 0.6910 - val_accuracy: 0.5331\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["   train_acc  train_f1  tune_acc   tune_f1  test_acc   test_f1\n","0   0.542364  0.542234  0.540139  0.537295  0.526994  0.525064\n","1   0.534762  0.533756  0.541808  0.541606  0.519326  0.516555\n","2   0.547543  0.546179  0.541286  0.541223  0.529185  0.527102\n","3   0.544623  0.543158  0.540347  0.540219  0.527046  0.521535\n","4   0.545670  0.544153  0.541234  0.540168  0.527411  0.519087\n","5   0.550463  0.546409  0.541182  0.540799  0.526420  0.502263\n","6   0.546717  0.546565  0.540034  0.532382  0.522351  0.497278\n","7   0.545615  0.545592  0.541234  0.534021  0.532680  0.532576\n","8   0.551730  0.546371  0.540347  0.540006  0.523760  0.506559\n","9   0.543632  0.542605  0.540504  0.540540  0.531636  0.531437\n","Attempt 11/12\n","Epoch 1/400\n","142/142 [==============================] - 41s 265ms/step - loss: 0.6956 - accuracy: 0.4970 - val_loss: 0.6931 - val_accuracy: 0.5089\n","Epoch 2/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6940 - accuracy: 0.5003 - val_loss: 0.6953 - val_accuracy: 0.4911\n","Epoch 3/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6935 - accuracy: 0.4990 - val_loss: 0.6929 - val_accuracy: 0.5114\n","Epoch 4/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6931 - accuracy: 0.5079 - val_loss: 0.6948 - val_accuracy: 0.4914\n","Epoch 5/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6926 - accuracy: 0.5049 - val_loss: 0.6955 - val_accuracy: 0.4916\n","Epoch 6/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6921 - accuracy: 0.5031 - val_loss: 0.6932 - val_accuracy: 0.4918\n","Epoch 7/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6916 - accuracy: 0.5037 - val_loss: 0.6930 - val_accuracy: 0.4969\n","Epoch 8/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6915 - accuracy: 0.5034 - val_loss: 0.6928 - val_accuracy: 0.5061\n","Epoch 9/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6900 - accuracy: 0.5117 - val_loss: 0.6924 - val_accuracy: 0.5099\n","Epoch 10/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6901 - accuracy: 0.5122 - val_loss: 0.6923 - val_accuracy: 0.5117\n","Epoch 11/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6902 - accuracy: 0.5060 - val_loss: 0.6923 - val_accuracy: 0.5093\n","Epoch 12/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6896 - accuracy: 0.5068 - val_loss: 0.6928 - val_accuracy: 0.5207\n","Epoch 13/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6918 - accuracy: 0.5098 - val_loss: 0.6926 - val_accuracy: 0.5147\n","Epoch 14/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6890 - accuracy: 0.5184 - val_loss: 0.6920 - val_accuracy: 0.5143\n","Epoch 15/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6889 - accuracy: 0.5156 - val_loss: 0.6933 - val_accuracy: 0.4921\n","Epoch 16/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6888 - accuracy: 0.5123 - val_loss: 0.6918 - val_accuracy: 0.5224\n","Epoch 17/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6888 - accuracy: 0.5129 - val_loss: 0.6926 - val_accuracy: 0.5073\n","Epoch 18/400\n","142/142 [==============================] - 37s 263ms/step - loss: 0.6894 - accuracy: 0.5168 - val_loss: 0.6918 - val_accuracy: 0.5266\n","Epoch 19/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6890 - accuracy: 0.5197 - val_loss: 0.6917 - val_accuracy: 0.5233\n","Epoch 20/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6886 - accuracy: 0.5166 - val_loss: 0.6910 - val_accuracy: 0.5254\n","Epoch 21/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6883 - accuracy: 0.5217 - val_loss: 0.6909 - val_accuracy: 0.5279\n","Epoch 22/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6880 - accuracy: 0.5208 - val_loss: 0.6909 - val_accuracy: 0.5252\n","Epoch 23/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6883 - accuracy: 0.5247 - val_loss: 0.6906 - val_accuracy: 0.5301\n","Epoch 24/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6870 - accuracy: 0.5247 - val_loss: 0.6918 - val_accuracy: 0.5142\n","Epoch 25/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6866 - accuracy: 0.5273 - val_loss: 0.6903 - val_accuracy: 0.5319\n","Epoch 26/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6867 - accuracy: 0.5331 - val_loss: 0.6897 - val_accuracy: 0.5352\n","Epoch 27/400\n","142/142 [==============================] - 37s 263ms/step - loss: 0.6863 - accuracy: 0.5300 - val_loss: 0.6906 - val_accuracy: 0.5359\n","Epoch 28/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6869 - accuracy: 0.5279 - val_loss: 0.6900 - val_accuracy: 0.5381\n","Epoch 29/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6860 - accuracy: 0.5318 - val_loss: 0.6898 - val_accuracy: 0.5356\n","Epoch 30/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6853 - accuracy: 0.5386 - val_loss: 0.6892 - val_accuracy: 0.5412\n","Epoch 31/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6861 - accuracy: 0.5383 - val_loss: 0.6888 - val_accuracy: 0.5386\n","Epoch 32/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6851 - accuracy: 0.5362 - val_loss: 0.6896 - val_accuracy: 0.5367\n","Epoch 33/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6854 - accuracy: 0.5387 - val_loss: 0.6888 - val_accuracy: 0.5406\n","Epoch 34/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6848 - accuracy: 0.5446 - val_loss: 0.6887 - val_accuracy: 0.5381\n","Epoch 35/400\n","142/142 [==============================] - 36s 255ms/step - loss: 0.6856 - accuracy: 0.5407 - val_loss: 0.6887 - val_accuracy: 0.5375\n","Epoch 36/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6842 - accuracy: 0.5472 - val_loss: 0.6889 - val_accuracy: 0.5391\n","Epoch 37/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6848 - accuracy: 0.5425 - val_loss: 0.6891 - val_accuracy: 0.5390\n","Epoch 38/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6836 - accuracy: 0.5421 - val_loss: 0.6890 - val_accuracy: 0.5385\n","Epoch 39/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6847 - accuracy: 0.5388 - val_loss: 0.6887 - val_accuracy: 0.5397\n","Epoch 40/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6839 - accuracy: 0.5425 - val_loss: 0.6901 - val_accuracy: 0.5338\n","Epoch 41/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6839 - accuracy: 0.5450 - val_loss: 0.6895 - val_accuracy: 0.5352\n","Epoch 42/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6838 - accuracy: 0.5419 - val_loss: 0.6895 - val_accuracy: 0.5385\n","Epoch 43/400\n","142/142 [==============================] - 36s 256ms/step - loss: 0.6833 - accuracy: 0.5457 - val_loss: 0.6898 - val_accuracy: 0.5381\n","Epoch 44/400\n","142/142 [==============================] - 36s 257ms/step - loss: 0.6841 - accuracy: 0.5442 - val_loss: 0.6894 - val_accuracy: 0.5351\n","Epoch 45/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6836 - accuracy: 0.5408 - val_loss: 0.6885 - val_accuracy: 0.5386\n","Epoch 46/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6832 - accuracy: 0.5415 - val_loss: 0.6906 - val_accuracy: 0.5365\n","Epoch 47/400\n","142/142 [==============================] - 36s 257ms/step - loss: 0.6825 - accuracy: 0.5400 - val_loss: 0.6907 - val_accuracy: 0.5375\n","Epoch 48/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6831 - accuracy: 0.5437 - val_loss: 0.6897 - val_accuracy: 0.5371\n","Epoch 49/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6826 - accuracy: 0.5430 - val_loss: 0.6923 - val_accuracy: 0.5286\n","Epoch 50/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6820 - accuracy: 0.5476 - val_loss: 0.6898 - val_accuracy: 0.5370\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["    train_acc  train_f1  tune_acc   tune_f1  test_acc   test_f1\n","0    0.542364  0.542234  0.540139  0.537295  0.526994  0.525064\n","1    0.534762  0.533756  0.541808  0.541606  0.519326  0.516555\n","2    0.547543  0.546179  0.541286  0.541223  0.529185  0.527102\n","3    0.544623  0.543158  0.540347  0.540219  0.527046  0.521535\n","4    0.545670  0.544153  0.541234  0.540168  0.527411  0.519087\n","5    0.550463  0.546409  0.541182  0.540799  0.526420  0.502263\n","6    0.546717  0.546565  0.540034  0.532382  0.522351  0.497278\n","7    0.545615  0.545592  0.541234  0.534021  0.532680  0.532576\n","8    0.551730  0.546371  0.540347  0.540006  0.523760  0.506559\n","9    0.543632  0.542605  0.540504  0.540540  0.531636  0.531437\n","10   0.546772  0.546714  0.541234  0.539617  0.528715  0.528622\n","Attempt 12/12\n","Epoch 1/400\n","142/142 [==============================] - 40s 264ms/step - loss: 0.6952 - accuracy: 0.5018 - val_loss: 0.6930 - val_accuracy: 0.5058\n","Epoch 2/400\n","142/142 [==============================] - 36s 257ms/step - loss: 0.6939 - accuracy: 0.5082 - val_loss: 0.6937 - val_accuracy: 0.4911\n","Epoch 3/400\n","142/142 [==============================] - 36s 257ms/step - loss: 0.6937 - accuracy: 0.5036 - val_loss: 0.6931 - val_accuracy: 0.5089\n","Epoch 4/400\n","142/142 [==============================] - 36s 257ms/step - loss: 0.6933 - accuracy: 0.5019 - val_loss: 0.6937 - val_accuracy: 0.4911\n","Epoch 5/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6924 - accuracy: 0.5043 - val_loss: 0.6929 - val_accuracy: 0.5089\n","Epoch 6/400\n","142/142 [==============================] - 36s 257ms/step - loss: 0.6919 - accuracy: 0.5006 - val_loss: 0.6930 - val_accuracy: 0.5089\n","Epoch 7/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6913 - accuracy: 0.5102 - val_loss: 0.6928 - val_accuracy: 0.5089\n","Epoch 8/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6908 - accuracy: 0.5155 - val_loss: 0.6937 - val_accuracy: 0.4933\n","Epoch 9/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6909 - accuracy: 0.5076 - val_loss: 0.6933 - val_accuracy: 0.4921\n","Epoch 10/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6907 - accuracy: 0.5020 - val_loss: 0.6931 - val_accuracy: 0.4920\n","Epoch 11/400\n","142/142 [==============================] - 36s 257ms/step - loss: 0.6899 - accuracy: 0.5068 - val_loss: 0.6928 - val_accuracy: 0.4951\n","Epoch 12/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6902 - accuracy: 0.5074 - val_loss: 0.6927 - val_accuracy: 0.5049\n","Epoch 13/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6896 - accuracy: 0.5116 - val_loss: 0.6925 - val_accuracy: 0.5089\n","Epoch 14/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6901 - accuracy: 0.5112 - val_loss: 0.6926 - val_accuracy: 0.5061\n","Epoch 15/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6897 - accuracy: 0.5112 - val_loss: 0.6924 - val_accuracy: 0.5150\n","Epoch 16/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6894 - accuracy: 0.5147 - val_loss: 0.6947 - val_accuracy: 0.5093\n","Epoch 17/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6895 - accuracy: 0.5137 - val_loss: 0.6936 - val_accuracy: 0.5229\n","Epoch 18/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6898 - accuracy: 0.5094 - val_loss: 0.6926 - val_accuracy: 0.5164\n","Epoch 19/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6892 - accuracy: 0.5155 - val_loss: 0.6924 - val_accuracy: 0.5193\n","Epoch 20/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6888 - accuracy: 0.5189 - val_loss: 0.6922 - val_accuracy: 0.5248\n","Epoch 21/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6887 - accuracy: 0.5171 - val_loss: 0.6926 - val_accuracy: 0.5112\n","Epoch 22/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6888 - accuracy: 0.5135 - val_loss: 0.6925 - val_accuracy: 0.5108\n","Epoch 23/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6892 - accuracy: 0.5182 - val_loss: 0.6924 - val_accuracy: 0.5283\n","Epoch 24/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6924 - accuracy: 0.5126 - val_loss: 0.6919 - val_accuracy: 0.5263\n","Epoch 25/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6911 - accuracy: 0.5163 - val_loss: 0.6919 - val_accuracy: 0.5169\n","Epoch 26/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6884 - accuracy: 0.5212 - val_loss: 0.6918 - val_accuracy: 0.5242\n","Epoch 27/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6877 - accuracy: 0.5271 - val_loss: 0.6917 - val_accuracy: 0.5157\n","Epoch 28/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6880 - accuracy: 0.5213 - val_loss: 0.6914 - val_accuracy: 0.5281\n","Epoch 29/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6874 - accuracy: 0.5284 - val_loss: 0.6913 - val_accuracy: 0.5236\n","Epoch 30/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6882 - accuracy: 0.5236 - val_loss: 0.6910 - val_accuracy: 0.5311\n","Epoch 31/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6875 - accuracy: 0.5264 - val_loss: 0.6909 - val_accuracy: 0.5253\n","Epoch 32/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6870 - accuracy: 0.5263 - val_loss: 0.6905 - val_accuracy: 0.5304\n","Epoch 33/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6866 - accuracy: 0.5340 - val_loss: 0.6905 - val_accuracy: 0.5288\n","Epoch 34/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6860 - accuracy: 0.5309 - val_loss: 0.6896 - val_accuracy: 0.5375\n","Epoch 35/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6870 - accuracy: 0.5327 - val_loss: 0.6904 - val_accuracy: 0.5297\n","Epoch 36/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6862 - accuracy: 0.5373 - val_loss: 0.6894 - val_accuracy: 0.5345\n","Epoch 37/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6855 - accuracy: 0.5349 - val_loss: 0.6895 - val_accuracy: 0.5370\n","Epoch 38/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6853 - accuracy: 0.5374 - val_loss: 0.6892 - val_accuracy: 0.5347\n","Epoch 39/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6863 - accuracy: 0.5380 - val_loss: 0.6896 - val_accuracy: 0.5394\n","Epoch 40/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6853 - accuracy: 0.5374 - val_loss: 0.6889 - val_accuracy: 0.5395\n","Epoch 41/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6843 - accuracy: 0.5424 - val_loss: 0.6883 - val_accuracy: 0.5382\n","Epoch 42/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6851 - accuracy: 0.5381 - val_loss: 0.6894 - val_accuracy: 0.5363\n","Epoch 43/400\n","142/142 [==============================] - 37s 263ms/step - loss: 0.6847 - accuracy: 0.5427 - val_loss: 0.6888 - val_accuracy: 0.5403\n","Epoch 44/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6849 - accuracy: 0.5391 - val_loss: 0.6888 - val_accuracy: 0.5400\n","Epoch 45/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6836 - accuracy: 0.5454 - val_loss: 0.6889 - val_accuracy: 0.5384\n","Epoch 46/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6843 - accuracy: 0.5387 - val_loss: 0.6890 - val_accuracy: 0.5405\n","Epoch 47/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6840 - accuracy: 0.5425 - val_loss: 0.6886 - val_accuracy: 0.5399\n","Epoch 48/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6836 - accuracy: 0.5432 - val_loss: 0.6901 - val_accuracy: 0.5347\n","Epoch 49/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6832 - accuracy: 0.5471 - val_loss: 0.6883 - val_accuracy: 0.5399\n","Epoch 50/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6838 - accuracy: 0.5432 - val_loss: 0.6890 - val_accuracy: 0.5360\n","Epoch 51/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6832 - accuracy: 0.5412 - val_loss: 0.6925 - val_accuracy: 0.5345\n","Epoch 52/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6833 - accuracy: 0.5456 - val_loss: 0.6892 - val_accuracy: 0.5379\n","Epoch 53/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6828 - accuracy: 0.5459 - val_loss: 0.6892 - val_accuracy: 0.5393\n","Epoch 54/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6831 - accuracy: 0.5431 - val_loss: 0.6914 - val_accuracy: 0.5360\n","Epoch 55/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6824 - accuracy: 0.5476 - val_loss: 0.6888 - val_accuracy: 0.5346\n","Epoch 56/400\n","142/142 [==============================] - 37s 258ms/step - loss: 0.6824 - accuracy: 0.5426 - val_loss: 0.6910 - val_accuracy: 0.5349\n","Epoch 57/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6824 - accuracy: 0.5459 - val_loss: 0.6897 - val_accuracy: 0.5383\n","Epoch 58/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6821 - accuracy: 0.5513 - val_loss: 0.6905 - val_accuracy: 0.5362\n","Epoch 59/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6821 - accuracy: 0.5451 - val_loss: 0.6890 - val_accuracy: 0.5420\n","Epoch 60/400\n","142/142 [==============================] - 37s 262ms/step - loss: 0.6826 - accuracy: 0.5485 - val_loss: 0.6900 - val_accuracy: 0.5322\n","Epoch 61/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6819 - accuracy: 0.5504 - val_loss: 0.6906 - val_accuracy: 0.5350\n","Epoch 62/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6825 - accuracy: 0.5486 - val_loss: 0.6907 - val_accuracy: 0.5372\n","Epoch 63/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6820 - accuracy: 0.5466 - val_loss: 0.6900 - val_accuracy: 0.5369\n","Epoch 64/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6818 - accuracy: 0.5489 - val_loss: 0.6903 - val_accuracy: 0.5334\n","Epoch 65/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6819 - accuracy: 0.5483 - val_loss: 0.6905 - val_accuracy: 0.5278\n","Epoch 66/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6818 - accuracy: 0.5484 - val_loss: 0.6921 - val_accuracy: 0.5325\n","Epoch 67/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6814 - accuracy: 0.5456 - val_loss: 0.6907 - val_accuracy: 0.5213\n","Epoch 68/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6809 - accuracy: 0.5512 - val_loss: 0.6914 - val_accuracy: 0.5368\n","Epoch 69/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6810 - accuracy: 0.5458 - val_loss: 0.6922 - val_accuracy: 0.5338\n","Epoch 70/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6808 - accuracy: 0.5517 - val_loss: 0.6922 - val_accuracy: 0.5351\n","Epoch 71/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6803 - accuracy: 0.5523 - val_loss: 0.6924 - val_accuracy: 0.5362\n","Epoch 72/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6802 - accuracy: 0.5501 - val_loss: 0.6908 - val_accuracy: 0.5330\n","Epoch 73/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6799 - accuracy: 0.5501 - val_loss: 0.6918 - val_accuracy: 0.5375\n","Epoch 74/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6791 - accuracy: 0.5522 - val_loss: 0.6917 - val_accuracy: 0.5324\n","Epoch 75/400\n","142/142 [==============================] - 37s 261ms/step - loss: 0.6793 - accuracy: 0.5532 - val_loss: 0.6914 - val_accuracy: 0.5370\n","Epoch 76/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6786 - accuracy: 0.5560 - val_loss: 0.6910 - val_accuracy: 0.5322\n","Epoch 77/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6802 - accuracy: 0.5531 - val_loss: 0.6905 - val_accuracy: 0.5342\n","Epoch 78/400\n","142/142 [==============================] - 37s 259ms/step - loss: 0.6792 - accuracy: 0.5560 - val_loss: 0.6912 - val_accuracy: 0.5309\n","Epoch 79/400\n","142/142 [==============================] - 37s 260ms/step - loss: 0.6788 - accuracy: 0.5569 - val_loss: 0.6918 - val_accuracy: 0.5299\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:455: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n","  warnings.warn('`model.predict_classes()` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["    train_acc  train_f1  tune_acc   tune_f1  test_acc   test_f1\n","0    0.542364  0.542234  0.540139  0.537295  0.526994  0.525064\n","1    0.534762  0.533756  0.541808  0.541606  0.519326  0.516555\n","2    0.547543  0.546179  0.541286  0.541223  0.529185  0.527102\n","3    0.544623  0.543158  0.540347  0.540219  0.527046  0.521535\n","4    0.545670  0.544153  0.541234  0.540168  0.527411  0.519087\n","5    0.550463  0.546409  0.541182  0.540799  0.526420  0.502263\n","6    0.546717  0.546565  0.540034  0.532382  0.522351  0.497278\n","7    0.545615  0.545592  0.541234  0.534021  0.532680  0.532576\n","8    0.551730  0.546371  0.540347  0.540006  0.523760  0.506559\n","9    0.543632  0.542605  0.540504  0.540540  0.531636  0.531437\n","10   0.546772  0.546714  0.541234  0.539617  0.528715  0.528622\n","11   0.551675  0.551389  0.542017  0.537753  0.528089  0.520694\n","time: 3h 40min 39s (started: 2021-06-12 15:06:30 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"quNZqLD0ydur","colab":{"base_uri":"https://localhost:8080/","height":438},"executionInfo":{"status":"ok","timestamp":1623523628883,"user_tz":-180,"elapsed":15,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}},"outputId":"59bcebca-cfd3-4895-8222-a1b1533dd8bd"},"source":["r = pd.DataFrame(results)\n","r.to_csv(tune_results_file)\n","r"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>attempt</th>\n","      <th>layers</th>\n","      <th>neurons</th>\n","      <th>lr</th>\n","      <th>train_time</th>\n","      <th>epochs</th>\n","      <th>train_acc</th>\n","      <th>train_f1</th>\n","      <th>tune_acc</th>\n","      <th>tune_f1</th>\n","      <th>test_acc</th>\n","      <th>test_f1</th>\n","      <th>tune_buy_percentage</th>\n","      <th>test_buy_percentage</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>64</td>\n","      <td>0.00100</td>\n","      <td>231.948045</td>\n","      <td>37</td>\n","      <td>0.542364</td>\n","      <td>0.542234</td>\n","      <td>0.540139</td>\n","      <td>0.537295</td>\n","      <td>0.526994</td>\n","      <td>0.525064</td>\n","      <td>0.508946</td>\n","      <td>0.50373</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>64</td>\n","      <td>0.00010</td>\n","      <td>250.118479</td>\n","      <td>40</td>\n","      <td>0.534762</td>\n","      <td>0.533756</td>\n","      <td>0.541808</td>\n","      <td>0.541606</td>\n","      <td>0.519326</td>\n","      <td>0.516555</td>\n","      <td>0.508946</td>\n","      <td>0.50373</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>64</td>\n","      <td>0.00001</td>\n","      <td>300.638985</td>\n","      <td>48</td>\n","      <td>0.547543</td>\n","      <td>0.546179</td>\n","      <td>0.541286</td>\n","      <td>0.541223</td>\n","      <td>0.529185</td>\n","      <td>0.527102</td>\n","      <td>0.508946</td>\n","      <td>0.50373</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>128</td>\n","      <td>0.00100</td>\n","      <td>598.633714</td>\n","      <td>38</td>\n","      <td>0.544623</td>\n","      <td>0.543158</td>\n","      <td>0.540347</td>\n","      <td>0.540219</td>\n","      <td>0.527046</td>\n","      <td>0.521535</td>\n","      <td>0.508946</td>\n","      <td>0.50373</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>128</td>\n","      <td>0.00010</td>\n","      <td>693.680244</td>\n","      <td>44</td>\n","      <td>0.545670</td>\n","      <td>0.544153</td>\n","      <td>0.541234</td>\n","      <td>0.540168</td>\n","      <td>0.527411</td>\n","      <td>0.519087</td>\n","      <td>0.508946</td>\n","      <td>0.50373</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>1</td>\n","      <td>128</td>\n","      <td>0.00001</td>\n","      <td>883.107152</td>\n","      <td>56</td>\n","      <td>0.550463</td>\n","      <td>0.546409</td>\n","      <td>0.541182</td>\n","      <td>0.540799</td>\n","      <td>0.526420</td>\n","      <td>0.502263</td>\n","      <td>0.508946</td>\n","      <td>0.50373</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>2</td>\n","      <td>64</td>\n","      <td>0.00100</td>\n","      <td>1155.700086</td>\n","      <td>82</td>\n","      <td>0.546717</td>\n","      <td>0.546565</td>\n","      <td>0.540034</td>\n","      <td>0.532382</td>\n","      <td>0.522351</td>\n","      <td>0.497278</td>\n","      <td>0.508946</td>\n","      <td>0.50373</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>2</td>\n","      <td>64</td>\n","      <td>0.00010</td>\n","      <td>734.972144</td>\n","      <td>52</td>\n","      <td>0.545615</td>\n","      <td>0.545592</td>\n","      <td>0.541234</td>\n","      <td>0.534021</td>\n","      <td>0.532680</td>\n","      <td>0.532576</td>\n","      <td>0.508946</td>\n","      <td>0.50373</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>2</td>\n","      <td>64</td>\n","      <td>0.00001</td>\n","      <td>1165.579606</td>\n","      <td>84</td>\n","      <td>0.551730</td>\n","      <td>0.546371</td>\n","      <td>0.540347</td>\n","      <td>0.540006</td>\n","      <td>0.523760</td>\n","      <td>0.506559</td>\n","      <td>0.508946</td>\n","      <td>0.50373</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>2</td>\n","      <td>128</td>\n","      <td>0.00100</td>\n","      <td>2107.586008</td>\n","      <td>57</td>\n","      <td>0.543632</td>\n","      <td>0.542605</td>\n","      <td>0.540504</td>\n","      <td>0.540540</td>\n","      <td>0.531636</td>\n","      <td>0.531437</td>\n","      <td>0.508946</td>\n","      <td>0.50373</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>128</td>\n","      <td>0.00010</td>\n","      <td>1848.064352</td>\n","      <td>50</td>\n","      <td>0.546772</td>\n","      <td>0.546714</td>\n","      <td>0.541234</td>\n","      <td>0.539617</td>\n","      <td>0.528715</td>\n","      <td>0.528622</td>\n","      <td>0.508946</td>\n","      <td>0.50373</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>128</td>\n","      <td>0.00001</td>\n","      <td>2910.352170</td>\n","      <td>79</td>\n","      <td>0.551675</td>\n","      <td>0.551389</td>\n","      <td>0.542017</td>\n","      <td>0.537753</td>\n","      <td>0.528089</td>\n","      <td>0.520694</td>\n","      <td>0.508946</td>\n","      <td>0.50373</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    attempt  layers  ...  tune_buy_percentage  test_buy_percentage\n","0         1       1  ...             0.508946              0.50373\n","1         2       1  ...             0.508946              0.50373\n","2         3       1  ...             0.508946              0.50373\n","3         4       1  ...             0.508946              0.50373\n","4         5       1  ...             0.508946              0.50373\n","5         6       1  ...             0.508946              0.50373\n","6         7       2  ...             0.508946              0.50373\n","7         8       2  ...             0.508946              0.50373\n","8         9       2  ...             0.508946              0.50373\n","9        10       2  ...             0.508946              0.50373\n","10       11       2  ...             0.508946              0.50373\n","11       12       2  ...             0.508946              0.50373\n","\n","[12 rows x 14 columns]"]},"metadata":{"tags":[]},"execution_count":30},{"output_type":"stream","text":["time: 42.3 ms (started: 2021-06-12 18:47:10 +00:00)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zjYv1HC_Jack","executionInfo":{"status":"ok","timestamp":1623523628884,"user_tz":-180,"elapsed":14,"user":{"displayName":"Andrei Moldovan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjND1a0im4IeEuS3SopzHZ1h-8SwgakusMPPMDolw=s64","userId":"11141977249155520045"}}},"source":[""],"execution_count":30,"outputs":[]}]}